{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to plot & fit fluxes from the original and updated UrbanVPRM to 3 eddy-covariance flux towers in 2018 & 2019\n",
    "\n",
    "# Generates figure 2 a & b of Madsen-Colford et al. 2025\n",
    "# *** Denotes sections of the code that should be changed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy import optimize as opt \n",
    "from scipy import odr\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import linear_model #for robust fitting\n",
    "from sklearn.metrics import r2_score, mean_squared_error #for analyzing robust fits\n",
    "import matplotlib.colors as clrs #for log color scale\n",
    "import matplotlib.patheffects as pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the original & updated UrbanVPRM 2018 fluxes over Borden Forest flux tower\n",
    "\n",
    "#*** CHANGE PATHS & FILENAMES ***\n",
    "VPRM_data=pd.read_csv('Borden_500m_V061_no_adjustments_2018/vprm_mixed_ISA_Borden_500m_V061_2018_no_adjustments.csv')\n",
    "Updated_VPRM_data=pd.read_csv('Borden_V061_500m_2018/vprm_GMIS_Toronto_ACI_SOLRIS_ISA_500m_Borden_V061_2018_no_PScale_adjusted_Topt_Ra_URB_parameters_fixed_gapfilled_LSWI_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Select the pixels that fall within the Borden Forest footprint & omit data to the NW\n",
    "\n",
    "VPRM_HoY0=np.zeros([8760,6])*np.nan\n",
    "VPRM_Index0=np.zeros([8760,6])*np.nan\n",
    "VPRM_GEE0=np.zeros([8760,6])*np.nan\n",
    "VPRM_Reco0=np.zeros([8760,6])*np.nan\n",
    "\n",
    "Updated_VPRM_HoY0=np.zeros([8760,6])*np.nan\n",
    "Updated_VPRM_Index0=np.zeros([8760,6])*np.nan\n",
    "Updated_VPRM_GEE0=np.zeros([8760,6])*np.nan\n",
    "Updated_VPRM_Reco0=np.zeros([8760,6])*np.nan\n",
    "\n",
    "h=0\n",
    "l=0\n",
    "for i in range(8760*105,8760*106): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*120,8760*122): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*135,8760*138): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For original VPRM only (original VPRM gives -GEE in output file, multiply by -1)\n",
    "VPRM_GEE0 = -VPRM_GEE0\n",
    "#Compute NEE\n",
    "VPRM_NEE0=VPRM_Reco0+VPRM_GEE0\n",
    "Updated_VPRM_NEE0=Updated_VPRM_Reco0+Updated_VPRM_GEE0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average pixels inside Borden footprint\n",
    "\n",
    "VPRM_Borden_2018_avg_DoY=np.mean(VPRM_HoY0, axis=1)/24+23/24\n",
    "VPRM_Borden_2018_avg_Index=np.mean(VPRM_Index0, axis=1)\n",
    "VPRM_Borden_2018_avg_GPP=-np.mean(VPRM_GEE0, axis=1)\n",
    "VPRM_Borden_2018_avg_Reco=np.mean(VPRM_Reco0, axis=1)\n",
    "VPRM_Borden_2018_avg_NEE=np.mean(VPRM_NEE0, axis=1)\n",
    "\n",
    "Updated_VPRM_Borden_2018_avg_DoY=np.mean(Updated_VPRM_HoY0, axis=1)/24+23/24\n",
    "Updated_VPRM_Borden_2018_avg_Index=np.mean(Updated_VPRM_Index0, axis=1)\n",
    "Updated_VPRM_Borden_2018_avg_GPP=-np.mean(Updated_VPRM_GEE0, axis=1)\n",
    "Updated_VPRM_Borden_2018_avg_Reco=np.mean(Updated_VPRM_Reco0, axis=1)\n",
    "Updated_VPRM_Borden_2018_avg_NEE=np.mean(Updated_VPRM_NEE0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Borden Fluxtower values\n",
    "\n",
    "#*** CHANGE PATH & FILENAME ***\n",
    "Borden_Fluxes=pd.read_csv('/Users/kitty/Documents/Research/SIF/Flux_Tower/2018_NEP_GPP_Borden.csv', index_col=0)\n",
    "\n",
    "Borden_dates=np.zeros([17520])*np.nan\n",
    "Borden_NEEgf_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_NEE_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_Rgf_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_GEPgf_fluxes=np.zeros([17520])*np.nan\n",
    "for i in range(0,17520):\n",
    "    Borden_dates[i]=Borden_Fluxes.iat[i,0]#This is in UTC time\n",
    "    Borden_NEEgf_fluxes[i]=-Borden_Fluxes.iat[i,5] #NEE (gap filled)\n",
    "    Borden_NEE_fluxes[i]=-Borden_Fluxes.iat[i,1]\n",
    "    Borden_Rgf_fluxes[i]=Borden_Fluxes.iat[i,6]\n",
    "    Borden_GEPgf_fluxes[i]=Borden_Fluxes.iat[i,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take hourly average of Borden fluxtower data\n",
    "Borden_GEPgf=np.zeros(np.shape(VPRM_Borden_2018_avg_GPP))*np.nan\n",
    "Borden_NEEgf=np.zeros(np.shape(VPRM_Borden_2018_avg_GPP))*np.nan\n",
    "Borden_Rgf=np.zeros(np.shape(VPRM_Borden_2018_avg_GPP))*np.nan\n",
    "Borden_NEE=np.zeros(np.shape(VPRM_Borden_2018_avg_GPP))*np.nan\n",
    "\n",
    "for i in range(np.int(len(Borden_dates)/2)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        Borden_GEPgf[i]=np.nanmean([Borden_GEPgf_fluxes[i*2],Borden_GEPgf_fluxes[i*2+1]])\n",
    "        Borden_NEEgf[i]=np.nanmean([Borden_NEEgf_fluxes[i*2],Borden_NEEgf_fluxes[i*2+1]])\n",
    "        Borden_Rgf[i]=np.nanmean([Borden_Rgf_fluxes[i*2],Borden_Rgf_fluxes[i*2+1]])\n",
    "        Borden_NEE[i]=np.nanmean([Borden_NEE_fluxes[i*2],Borden_NEE_fluxes[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a linear function and a straight line for plotting\n",
    "def func2(x,m,b):\n",
    "    return m*x+b\n",
    "\n",
    "line1_1=np.arange(-100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a daily average of VPRM fluxes over Borden Forest flux tower\n",
    "date_array_2018=np.arange(np.nanmin(VPRM_Borden_2018_avg_DoY),366,1/24)\n",
    "\n",
    "VPRM_daily_NEE_Borden_2018=np.zeros(365)*np.nan\n",
    "VPRM_daily_GPP_Borden_2018=np.zeros(365)*np.nan\n",
    "VPRM_daily_R_Borden_2018=np.zeros(365)*np.nan\n",
    "\n",
    "Updated_VPRM_daily_NEE_Borden_2018=np.zeros(365)*np.nan\n",
    "Updated_VPRM_daily_GPP_Borden_2018=np.zeros(365)*np.nan\n",
    "Updated_VPRM_daily_R_Borden_2018=np.zeros(365)*np.nan\n",
    "date=0\n",
    "\n",
    "daily_NEE_VPRM=[]\n",
    "daily_GPP_VPRM=[]\n",
    "daily_R_VPRM=[]\n",
    "\n",
    "daily_NEE_Updated_VPRM=[]\n",
    "daily_GPP_Updated_VPRM=[]\n",
    "daily_R_Updated_VPRM=[]\n",
    "for i in range(len(date_array_2018)):\n",
    "    if np.round(date_array_2018[i],4)>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_VPRM.append(VPRM_Borden_2018_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_Borden_2018_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_Borden_2018_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_Borden_2018_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_Borden_2018_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_Borden_2018_avg_Reco[i])\n",
    "            if i==len(date_array_2018)-1:\n",
    "                VPRM_daily_NEE_Borden_2018[date]=np.mean(daily_NEE_VPRM)\n",
    "                VPRM_daily_GPP_Borden_2018[date]=np.mean(daily_GPP_VPRM)\n",
    "                VPRM_daily_R_Borden_2018[date]=np.mean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_daily_NEE_Borden_2018[date]=np.mean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_daily_GPP_Borden_2018[date]=np.mean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_daily_R_Borden_2018[date]=np.mean(daily_R_Updated_VPRM)\n",
    "                date+=1\n",
    "\n",
    "        else:\n",
    "            daily_NEE_VPRM.append(VPRM_Borden_2018_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_Borden_2018_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_Borden_2018_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_Borden_2018_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_Borden_2018_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_Borden_2018_avg_Reco[i])\n",
    "            if np.floor(np.round(date_array_2018[i],4))<np.floor(np.round(date_array_2018[i+1],4)):\n",
    "                VPRM_daily_NEE_Borden_2018[date]=np.mean(daily_NEE_VPRM)\n",
    "                VPRM_daily_GPP_Borden_2018[date]=np.mean(daily_GPP_VPRM)\n",
    "                VPRM_daily_R_Borden_2018[date]=np.mean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_daily_NEE_Borden_2018[date]=np.mean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_daily_GPP_Borden_2018[date]=np.mean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_daily_R_Borden_2018[date]=np.mean(daily_R_Updated_VPRM)\n",
    "                \n",
    "                date+=1\n",
    "                daily_NEE_VPRM=[]\n",
    "                daily_GPP_VPRM=[]\n",
    "                daily_R_VPRM=[]\n",
    "                \n",
    "                daily_NEE_Updated_VPRM=[]\n",
    "                daily_GPP_Updated_VPRM=[]\n",
    "                daily_R_Updated_VPRM=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the daily average of Borden forest flux tower data\n",
    "days_of_year=np.arange(1,366)+0.5\n",
    "\n",
    "Borden_daily_mean_NEE=np.zeros(365)*np.nan\n",
    "Borden_daily_mean_NEEgf=np.zeros(365)*np.nan\n",
    "Borden_daily_mean_GPPgf=np.zeros(365)*np.nan\n",
    "Borden_daily_mean_Rgf=np.zeros(365)*np.nan\n",
    "\n",
    "for i in range(len(days_of_year)):\n",
    "    daily_NEE_Borden_2018=Borden_NEE[np.floor(np.round(VPRM_Borden_2018_avg_DoY,4))==i+1]\n",
    "    daily_NEEgf_Borden_2018=Borden_NEEgf[np.floor(np.round(VPRM_Borden_2018_avg_DoY,4))==i+1]\n",
    "    daily_GPPgf_Borden_2018=Borden_GEPgf[np.floor(np.round(VPRM_Borden_2018_avg_DoY,4))==i+1]\n",
    "    daily_Rgf_Borden_2018=Borden_Rgf[np.floor(np.round(VPRM_Borden_2018_avg_DoY,4))==i+1]\n",
    "    if len(daily_NEE_Borden_2018)==24:\n",
    "        Borden_daily_mean_NEE[i]=np.mean(daily_NEE_Borden_2018)\n",
    "        Borden_daily_mean_NEEgf[i]=np.mean(daily_NEEgf_Borden_2018)\n",
    "        Borden_daily_mean_GPPgf[i]=np.mean(daily_GPPgf_Borden_2018)\n",
    "        Borden_daily_mean_Rgf[i]=np.mean(daily_Rgf_Borden_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in UrbanVPRM data over TP39\n",
    "\n",
    "#*** CHANGE PATHS & FILENAMES ***\n",
    "VPRM_data=pd.read_csv('TP39_500m_V061_no_adjustments_2018/vprm_mixed_ISA_TP39_500m_V061_2018_no_adjustments.csv')\n",
    "Updated_VPRM_data=pd.read_csv('TP39_V061_500m_2018/vprm_GMIS_Toronto_ACI_SOLRIS_ISA_500m_TP39_V061_2018_no_PScale_adjusted_Topt_Ra_URB_parameters_fixed_gapfilled_LSWI_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data in the footprint of the TP39 tower\n",
    "VPRM_HoY0=np.zeros([8760,4])*np.nan\n",
    "VPRM_Index0=np.zeros([8760,4])*np.nan\n",
    "VPRM_GEE0=np.zeros([8760,4])*np.nan\n",
    "VPRM_Reco0=np.zeros([8760,4])*np.nan\n",
    "\n",
    "Updated_VPRM_HoY0=np.zeros([8760,4])*np.nan\n",
    "Updated_VPRM_Index0=np.zeros([8760,4])*np.nan\n",
    "Updated_VPRM_GEE0=np.zeros([8760,4])*np.nan\n",
    "Updated_VPRM_Reco0=np.zeros([8760,4])*np.nan\n",
    "h=0\n",
    "l=0\n",
    "for i in range(8760*119,8760*121): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*135,8760*137): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "\n",
    "#Compute NEE\n",
    "VPRM_GEE0=-VPRM_GEE0 #ONLY FOR ORIGINAL VPRM\n",
    "VPRM_NEE0=VPRM_Reco0+VPRM_GEE0\n",
    "Updated_VPRM_NEE0=Updated_VPRM_Reco0+Updated_VPRM_GEE0\n",
    "\n",
    "#Take the average over all the pixels\n",
    "VPRM_TP39_2018_avg_DoY=np.mean(VPRM_HoY0, axis=1)/24+23/24 #This makes it so that the HoY=1 is midnight on January 1st i.e. DoY= 1.00\n",
    "VPRM_TP39_2018_avg_Index=np.mean(VPRM_Index0, axis=1)\n",
    "VPRM_TP39_2018_avg_GPP=-np.mean(VPRM_GEE0, axis=1)\n",
    "VPRM_TP39_2018_avg_Reco=np.mean(VPRM_Reco0, axis=1)\n",
    "VPRM_TP39_2018_avg_NEE=np.mean(VPRM_NEE0, axis=1)\n",
    "\n",
    "Updated_VPRM_TP39_2018_avg_DoY=np.mean(Updated_VPRM_HoY0, axis=1)/24+23/24 #This makes it so that the HoY=1 is midnight on January 1st i.e. DoY= 1.00\n",
    "Updated_VPRM_TP39_2018_avg_Index=np.mean(Updated_VPRM_Index0, axis=1)\n",
    "Updated_VPRM_TP39_2018_avg_GPP=-np.mean(Updated_VPRM_GEE0, axis=1)\n",
    "Updated_VPRM_TP39_2018_avg_Reco=np.mean(Updated_VPRM_Reco0, axis=1)\n",
    "Updated_VPRM_TP39_2018_avg_NEE=np.mean(Updated_VPRM_NEE0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import TP39 2018 flux tower data\n",
    "\n",
    "#*** CHANGE PATH & FILENAME ***\n",
    "TP39_Fluxes=pd.read_csv('/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TP39_HH_2018.csv', usecols=[0,1,2,77,78,79])\n",
    "\n",
    "TP39_dates=np.zeros([17520])*np.nan\n",
    "TP39_NEEgf_fluxes=np.zeros([17520])*np.nan\n",
    "TP39_NEE_fluxes=np.zeros([17520])*np.nan\n",
    "TP39_Rgf_fluxes=np.zeros([17520])*np.nan\n",
    "TP39_GPPgf_fluxes=np.zeros([17520])*np.nan\n",
    "for i in range(0,17520):\n",
    "    if 201801010000<=TP39_Fluxes.iat[i,0]<201901010000:\n",
    "        #Convert to UTC time by adding 5/24 to date\n",
    "        TP39_dates[i]= datetime.strptime(str(int(TP39_Fluxes.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TP39_Fluxes.iat[i,0])[8:10])+float(str(TP39_Fluxes.iat[i,0])[10:12])/60)/24+5/24\n",
    "        TP39_NEEgf_fluxes[i]=TP39_Fluxes.iat[i,5] #NEE (gap filled)\n",
    "        if TP39_Fluxes.iat[i,2]>-9999:\n",
    "            TP39_NEE_fluxes[i]=TP39_Fluxes.iat[i,2]\n",
    "        TP39_Rgf_fluxes[i]=TP39_Fluxes.iat[i,4]\n",
    "        TP39_GPPgf_fluxes[i]=TP39_Fluxes.iat[i,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take hourly average\n",
    "TP39_GPP=np.zeros(np.shape(VPRM_TP39_2018_avg_GPP))*np.nan\n",
    "TP39_NEE=np.zeros(np.shape(VPRM_TP39_2018_avg_GPP))*np.nan\n",
    "TP39_NEEgf=np.zeros(np.shape(VPRM_TP39_2018_avg_GPP))*np.nan\n",
    "TP39_R=np.zeros(np.shape(VPRM_TP39_2018_avg_GPP))*np.nan\n",
    "\n",
    "for i in range(np.int(len(TP39_dates)/2)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        if i<8755:\n",
    "            TP39_GPP[i+5]=np.nanmean([TP39_GPPgf_fluxes[i*2],TP39_GPPgf_fluxes[i*2+1]])\n",
    "            TP39_NEE[i+5]=np.nanmean([TP39_NEE_fluxes[i*2],TP39_NEE_fluxes[i*2+1]])\n",
    "            TP39_NEEgf[i+5]=np.nanmean([TP39_NEEgf_fluxes[i*2],TP39_NEEgf_fluxes[i*2+1]])\n",
    "            TP39_R[i+5]=np.nanmean([TP39_Rgf_fluxes[i*2],TP39_Rgf_fluxes[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take daily average of 2018 VPRM data at TP39\n",
    "\n",
    "VPRM_TP39_2018_daily_NEE=np.zeros(365)*np.nan\n",
    "VPRM_TP39_2018_daily_GPP=np.zeros(365)*np.nan\n",
    "VPRM_TP39_2018_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "Updated_VPRM_TP39_2018_daily_NEE=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TP39_2018_daily_GPP=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TP39_2018_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "date=0\n",
    "daily_NEE_VPRM=[]\n",
    "daily_GPP_VPRM=[]\n",
    "daily_R_VPRM=[]\n",
    "daily_NEE_Updated_VPRM=[]\n",
    "daily_GPP_Updated_VPRM=[]\n",
    "daily_R_Updated_VPRM=[]\n",
    "for i in range(len(VPRM_TP39_2018_avg_DoY)):\n",
    "    if VPRM_TP39_2018_avg_DoY[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_VPRM.append(VPRM_TP39_2018_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TP39_2018_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TP39_2018_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TP39_2018_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TP39_2018_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TP39_2018_avg_Reco[i])\n",
    "            if i==len(VPRM_TP39_2018_avg_DoY)-1:\n",
    "                VPRM_TP39_2018_daily_NEE[date]=np.mean(daily_NEE_VPRM)\n",
    "                VPRM_TP39_2018_daily_GPP[date]=np.mean(daily_GPP_VPRM)\n",
    "                VPRM_TP39_2018_daily_R[date]=np.mean(daily_R_VPRM)\n",
    "                 \n",
    "                Updated_VPRM_TP39_2018_daily_NEE[date]=np.mean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2018_daily_GPP[date]=np.mean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2018_daily_R[date]=np.mean(daily_R_Updated_VPRM)\n",
    "                \n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_VPRM.append(VPRM_TP39_2018_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TP39_2018_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TP39_2018_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TP39_2018_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TP39_2018_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TP39_2018_avg_Reco[i])\n",
    "            if np.floor(np.round(VPRM_TP39_2018_avg_DoY[i],4))<np.floor(np.round(VPRM_TP39_2018_avg_DoY[i+1],4)):\n",
    "                VPRM_TP39_2018_daily_NEE[date]=np.mean(daily_NEE_VPRM)\n",
    "                VPRM_TP39_2018_daily_GPP[date]=np.mean(daily_GPP_VPRM)\n",
    "                VPRM_TP39_2018_daily_R[date]=np.mean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TP39_2018_daily_NEE[date]=np.mean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2018_daily_GPP[date]=np.mean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2018_daily_R[date]=np.mean(daily_R_Updated_VPRM)\n",
    "                date+=1\n",
    "                \n",
    "                daily_NEE_VPRM=[]\n",
    "                daily_GPP_VPRM=[]\n",
    "                daily_R_VPRM=[]\n",
    "                \n",
    "                daily_NEE_Updated_VPRM=[]\n",
    "                daily_GPP_Updated_VPRM=[]\n",
    "                daily_R_Updated_VPRM=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take daily average of 2018 TP39 flux tower data\n",
    "\n",
    "TP39_daily_mean_NEE=np.zeros(365)*np.nan\n",
    "TP39_daily_mean_GPP=np.zeros(365)*np.nan\n",
    "TP39_daily_mean_R=np.zeros(365)*np.nan\n",
    "TP39_daily_mean_NEEgf=np.zeros(365)*np.nan\n",
    "\n",
    "for i in range(len(days_of_year)):\n",
    "    daily_NEEgf_TP39_2018=TP39_NEEgf[np.floor(np.round(VPRM_TP39_2018_avg_DoY,4))==i+1]\n",
    "    daily_NEE_TP39_2018=TP39_NEE[np.floor(np.round(VPRM_TP39_2018_avg_DoY,4))==i+1]\n",
    "    daily_GPP_TP39_2018=TP39_GPP[np.floor(np.round(VPRM_TP39_2018_avg_DoY,4))==i+1]\n",
    "    daily_R_TP39_2018=TP39_R[np.floor(np.round(VPRM_TP39_2018_avg_DoY,4))==i+1]\n",
    "    if len(daily_NEE_TP39_2018)==24:\n",
    "        TP39_daily_mean_NEEgf[i]=np.mean(daily_NEEgf_TP39_2018)\n",
    "        TP39_daily_mean_NEE[i]=np.mean(daily_NEE_TP39_2018)\n",
    "        TP39_daily_mean_GPP[i]=np.mean(daily_GPP_TP39_2018)\n",
    "        TP39_daily_mean_R[i]=np.mean(daily_R_TP39_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in UrbanVPRM 2019 fluxes over TP39 \n",
    "# *** CHANGE PATHS & FILENAMES ***\n",
    "VPRM_data=pd.read_csv('TP39_500m_V061_no_adjustments_2019/vprm_mixed_ISA_TP39_500m_V061_2019_no_adjustments.csv')\n",
    "Updated_VPRM_data=pd.read_csv('TP39_V061_500m_2019/vprm_GMIS_Toronto_ACI_SOLRIS_ISA_500m_TP39_V061_2019_no_PScale_adjusted_Topt_Ra_URB_parameters_fixed_gapfilled_LSWI_filtered.csv')\n",
    "\n",
    "#Select data in footprint of tower\n",
    "VPRM_HoY0=np.zeros([8760,4])*np.nan\n",
    "VPRM_Index0=np.zeros([8760,4])*np.nan\n",
    "VPRM_GEE0=np.zeros([8760,4])*np.nan\n",
    "VPRM_Reco0=np.zeros([8760,4])*np.nan\n",
    "\n",
    "Updated_VPRM_HoY0=np.zeros([8760,4])*np.nan\n",
    "Updated_VPRM_Index0=np.zeros([8760,4])*np.nan\n",
    "Updated_VPRM_GEE0=np.zeros([8760,4])*np.nan\n",
    "Updated_VPRM_Reco0=np.zeros([8760,4])*np.nan\n",
    "h=0\n",
    "l=0\n",
    "for i in range(8760*119,8760*121): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*135,8760*137): # *** NOTE: if extent is changed in UrbanVPRM code these indices will need to be changed ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]    \n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "\n",
    "VPRM_GEE0=-VPRM_GEE0 #ONLY FOR ORIGINAL UrbanVPRM\n",
    "VPRM_NEE0=VPRM_Reco0+VPRM_GEE0\n",
    "Updated_VPRM_NEE0=Updated_VPRM_Reco0+Updated_VPRM_GEE0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average pixels that fall within TP39's footprint\n",
    "\n",
    "#Original UrbanVPRM\n",
    "VPRM_TP39_2019_avg_DoY=np.mean(VPRM_HoY0, axis=1)/24+23/24\n",
    "VPRM_TP39_2019_avg_Index=np.mean(VPRM_Index0, axis=1)\n",
    "VPRM_TP39_2019_avg_GPP=-np.mean(VPRM_GEE0, axis=1)\n",
    "VPRM_TP39_2019_avg_Reco=np.mean(VPRM_Reco0, axis=1)\n",
    "VPRM_TP39_2019_avg_NEE=np.mean(VPRM_NEE0, axis=1)\n",
    "\n",
    "#Updated UrbanVPRM\n",
    "Updated_VPRM_TP39_2019_avg_DoY=np.mean(Updated_VPRM_HoY0, axis=1)/24+23/24\n",
    "Updated_VPRM_TP39_2019_avg_Index=np.mean(Updated_VPRM_Index0, axis=1)\n",
    "Updated_VPRM_TP39_2019_avg_GPP=-np.mean(Updated_VPRM_GEE0, axis=1)\n",
    "Updated_VPRM_TP39_2019_avg_Reco=np.mean(Updated_VPRM_Reco0, axis=1)\n",
    "Updated_VPRM_TP39_2019_avg_NEE=np.mean(Updated_VPRM_NEE0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in TP39 2019 data (in local time)\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "TP39_2019_Fluxes=pd.read_csv('/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TP39_HH_2019.csv',usecols=(0,2,77,78,79))\n",
    "\n",
    "TP39_2019_dates=np.zeros([17520])*np.nan\n",
    "TP39_2019_NEEgf_fluxes=np.zeros([17520])*np.nan\n",
    "TP39_2019_NEE_fluxes=np.zeros([17520])*np.nan\n",
    "TP39_2019_Rgf_fluxes=np.zeros([17520])*np.nan\n",
    "TP39_2019_GPPgf_fluxes=np.zeros([17520])*np.nan\n",
    "\n",
    "for i in range(0,17520):\n",
    "    if 201901010000<=TP39_2019_Fluxes.iat[i,0]<202001010000:\n",
    "        #TP is 5 hours behind UTC adjust to UTC\n",
    "        TP39_2019_dates[i]=datetime.strptime(str(int(TP39_2019_Fluxes.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TP39_2019_Fluxes.iat[i,0])[8:10])+float(str(TP39_2019_Fluxes.iat[i,0])[10:12])/60)/24+5/24\n",
    "        if TP39_2019_Fluxes.iat[i,4]>-9999:\n",
    "            TP39_2019_NEEgf_fluxes[i]=TP39_2019_Fluxes.iat[i,4] #NEE (gap filled)\n",
    "        if TP39_2019_Fluxes.iat[i,1]>-9999:\n",
    "            TP39_2019_NEE_fluxes[i]=TP39_2019_Fluxes.iat[i,1]\n",
    "        if TP39_2019_Fluxes.iat[i,3]>-9999:\n",
    "            TP39_2019_Rgf_fluxes[i]=TP39_2019_Fluxes.iat[i,3]\n",
    "        if TP39_2019_Fluxes.iat[i,2]>-9999:\n",
    "            TP39_2019_GPPgf_fluxes[i]=TP39_2019_Fluxes.iat[i,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take hourly average\n",
    "TP39_2019_GPP=np.zeros(np.shape(VPRM_TP39_2019_avg_GPP))*np.nan\n",
    "TP39_2019_NEE=np.zeros(np.shape(VPRM_TP39_2019_avg_GPP))*np.nan\n",
    "TP39_2019_NEEgf=np.zeros(np.shape(VPRM_TP39_2019_avg_GPP))*np.nan\n",
    "TP39_2019_R=np.zeros(np.shape(VPRM_TP39_2019_avg_GPP))*np.nan\n",
    "for i in range(np.int(len(TP39_2019_dates)/2)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        if i<8755:\n",
    "            TP39_2019_GPP[i+5]=np.nanmean([TP39_2019_GPPgf_fluxes[i*2],TP39_2019_GPPgf_fluxes[i*2+1]])\n",
    "            TP39_2019_NEE[i+5]=np.nanmean([TP39_2019_NEE_fluxes[i*2],TP39_2019_NEE_fluxes[i*2+1]])\n",
    "            TP39_2019_NEEgf[i+5]=np.nanmean([TP39_2019_NEEgf_fluxes[i*2],TP39_2019_NEEgf_fluxes[i*2+1]])\n",
    "            TP39_2019_R[i+5]=np.nanmean([TP39_2019_Rgf_fluxes[i*2],TP39_2019_Rgf_fluxes[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take daily average of UrbanVPRM 2019 data over TP39\n",
    "VPRM_TP39_2019_daily_NEE=np.zeros(365)*np.nan\n",
    "VPRM_TP39_2019_daily_GPP=np.zeros(365)*np.nan\n",
    "VPRM_TP39_2019_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "Updated_VPRM_TP39_2019_daily_NEE=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TP39_2019_daily_GPP=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TP39_2019_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "date=0\n",
    "daily_NEE_VPRM=[]\n",
    "daily_GPP_VPRM=[]\n",
    "daily_R_VPRM=[]\n",
    "daily_NEE_Updated_VPRM=[]\n",
    "daily_GPP_Updated_VPRM=[]\n",
    "daily_R_Updated_VPRM=[]\n",
    "\n",
    "for i in range(len(VPRM_TP39_2019_avg_DoY)):\n",
    "    if VPRM_TP39_2019_avg_DoY[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_VPRM.append(VPRM_TP39_2019_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TP39_2019_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TP39_2019_avg_Reco[i])\n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TP39_2019_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TP39_2019_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TP39_2019_avg_Reco[i])\n",
    "            if i==len(VPRM_TP39_2019_avg_DoY)-1:\n",
    "                VPRM_TP39_2019_daily_NEE[date]=np.mean(daily_NEE_VPRM)\n",
    "                VPRM_TP39_2019_daily_GPP[date]=np.mean(daily_GPP_VPRM)\n",
    "                VPRM_TP39_2019_daily_R[date]=np.mean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TP39_2019_daily_NEE[date]=np.mean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2019_daily_GPP[date]=np.mean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2019_daily_R[date]=np.mean(daily_R_Updated_VPRM)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_VPRM.append(VPRM_TP39_2019_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TP39_2019_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TP39_2019_avg_Reco[i])\n",
    "        \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TP39_2019_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TP39_2019_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TP39_2019_avg_Reco[i])\n",
    "            if np.floor(np.round(VPRM_TP39_2019_avg_DoY[i],4))<np.floor(np.round(VPRM_TP39_2019_avg_DoY[i+1],4)):\n",
    "                VPRM_TP39_2019_daily_NEE[date]=np.mean(daily_NEE_VPRM)\n",
    "                VPRM_TP39_2019_daily_GPP[date]=np.mean(daily_GPP_VPRM)\n",
    "                VPRM_TP39_2019_daily_R[date]=np.mean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TP39_2019_daily_NEE[date]=np.mean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2019_daily_GPP[date]=np.mean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TP39_2019_daily_R[date]=np.mean(daily_R_Updated_VPRM)\n",
    "                \n",
    "                date+=1\n",
    "                daily_NEE_VPRM=[]\n",
    "                daily_GPP_VPRM=[]\n",
    "                daily_R_VPRM=[]\n",
    "                \n",
    "                daily_NEE_Updated_VPRM=[]\n",
    "                daily_GPP_Updated_VPRM=[]\n",
    "                daily_R_Updated_VPRM=[]\n",
    "         \n",
    "        \n",
    "#Take daily average of TP39 2019 flux tower data\n",
    "TP39_2019_daily_mean_NEE=np.zeros(365)*np.nan\n",
    "TP39_2019_daily_mean_GPP=np.zeros(365)*np.nan\n",
    "TP39_2019_daily_mean_R=np.zeros(365)*np.nan\n",
    "TP39_2019_daily_mean_NEEgf=np.zeros(365)*np.nan\n",
    "\n",
    "for i in range(len(days_of_year)):\n",
    "    daily_NEEgf_TP39_2019=TP39_2019_NEEgf[np.floor(np.round(VPRM_TP39_2019_avg_DoY,4))==i+1]\n",
    "    daily_NEE_TP39_2019=TP39_2019_NEE[np.floor(np.round(VPRM_TP39_2019_avg_DoY,4))==i+1]\n",
    "    daily_GPP_TP39_2019=TP39_2019_GPP[np.floor(np.round(VPRM_TP39_2019_avg_DoY,4))==i+1]\n",
    "    daily_R_TP39_2019=TP39_2019_R[np.floor(np.round(VPRM_TP39_2019_avg_DoY,4))==i+1]\n",
    "    if len(daily_NEE_TP39_2019)==24:\n",
    "        TP39_2019_daily_mean_NEEgf[i]=np.mean(daily_NEEgf_TP39_2019)\n",
    "        TP39_2019_daily_mean_NEE[i]=np.mean(daily_NEE_TP39_2019)\n",
    "        TP39_2019_daily_mean_GPP[i]=np.mean(daily_GPP_TP39_2019)\n",
    "        TP39_2019_daily_mean_R[i]=np.mean(daily_R_TP39_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in 2018 UrbanVPRM data over TPD\n",
    "\n",
    "#*** CHANGE PATHS & FILENAMES\n",
    "VPRM_data=pd.read_csv('TPD_500m_V061_no_adjustments_2018/vprm_mixed_ISA_TPD_500m_V061_2018_no_adjustments.csv')\n",
    "Updated_VPRM_data=pd.read_csv('TPD_V061_500m_2018/vprm_GMIS_Toronto_ACI_SOLRIS_ISA_500m_TPD_V061_2018_no_PScale_adjusted_Topt_Ra_URB_parameters_fixed_gapfilled_LSWI_filtered.csv')\n",
    "\n",
    "VPRM_HoY0=np.zeros([8760,9])*np.nan\n",
    "VPRM_Index0=np.zeros([8760,9])*np.nan\n",
    "VPRM_GEE0=np.zeros([8760,9])*np.nan\n",
    "VPRM_Reco0=np.zeros([8760,9])*np.nan\n",
    "\n",
    "Updated_VPRM_HoY0=np.zeros([8760,9])*np.nan\n",
    "Updated_VPRM_Index0=np.zeros([8760,9])*np.nan\n",
    "Updated_VPRM_GEE0=np.zeros([8760,9])*np.nan\n",
    "Updated_VPRM_Reco0=np.zeros([8760,9])*np.nan\n",
    "h=0\n",
    "l=0\n",
    "for i in range(8760*103,8760*106): # *** NOTE: If you changed the extent in UrbanVPRM you will need to adjust these indices ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*119,8760*122): # *** NOTE: If you changed the extent in UrbanVPRM you will need to adjust these indices *** \n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*135,8760*138): # *** NOTE: If you changed the extent in UrbanVPRM you will need to adjust these indices ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "        \n",
    "#Take the average of all data that falls inside the TPD flux tower footprint\n",
    "VPRM_TPD_avg_DoY=np.nanmean(VPRM_HoY0, axis=1)/24+23/24 #convert from hour 1 to DoY=1\n",
    "VPRM_TPD_avg_Index=np.nanmean(VPRM_Index0, axis=1)\n",
    "VPRM_TPD_avg_GPP=np.nanmean(VPRM_GEE0, axis=1) #- for updated version\n",
    "VPRM_TPD_avg_Reco=np.nanmean(VPRM_Reco0, axis=1)\n",
    "VPRM_TPD_avg_NEE=np.nanmean(VPRM_Reco0-VPRM_GEE0, axis=1) #switch sign for updated version\n",
    "\n",
    "Updated_VPRM_TPD_avg_DoY=np.nanmean(Updated_VPRM_HoY0, axis=1)/24+23/24 #convert from hour 1 to DoY=1\n",
    "Updated_VPRM_TPD_avg_Index=np.nanmean(Updated_VPRM_Index0, axis=1)\n",
    "Updated_VPRM_TPD_avg_GPP=np.nanmean(-Updated_VPRM_GEE0, axis=1) #- for updated version\n",
    "Updated_VPRM_TPD_avg_Reco=np.nanmean(Updated_VPRM_Reco0, axis=1)\n",
    "Updated_VPRM_TPD_avg_NEE=np.nanmean(Updated_VPRM_Reco0+Updated_VPRM_GEE0, axis=1) #switch sign for updated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in TPD 2018 flux tower fluxes\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "TPD_Fluxes=pd.read_csv('/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TPD_HH_2018.csv', usecols=(0,2,74,75,76))\n",
    "\n",
    "TPD_dates=np.zeros([17520])*np.nan\n",
    "TPD_NEEgf_fluxes=np.zeros([17520])*np.nan\n",
    "TPD_NEE_fluxes=np.zeros([17520])*np.nan\n",
    "TPD_Rgf_fluxes=np.zeros([17520])*np.nan\n",
    "TPD_GPPgf_fluxes=np.zeros([17520])*np.nan\n",
    "\n",
    "for i in range(0,17520):\n",
    "    if 201801010000<=TPD_Fluxes.iat[i,0]<201901010000:\n",
    "        #TP is 5 hours behind UTC #adjust to UTC\n",
    "        TPD_dates[i]=datetime.strptime(str(int(TPD_Fluxes.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TPD_Fluxes.iat[i,0])[8:10])+float(str(TPD_Fluxes.iat[i,0])[10:12])/60)/24+5/24\n",
    "\n",
    "        TPD_NEEgf_fluxes[i]=TPD_Fluxes.iat[i,4] #NEE (gap filled)\n",
    "        if TPD_Fluxes.iat[i,1]>-9999:\n",
    "            TPD_NEE_fluxes[i]=TPD_Fluxes.iat[i,1] #NEE (non-gapfilled)\n",
    "        TPD_Rgf_fluxes[i]=TPD_Fluxes.iat[i,3]\n",
    "        TPD_GPPgf_fluxes[i]=TPD_Fluxes.iat[i,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPD_GPP=np.zeros(np.shape(VPRM_TPD_avg_GPP))*np.nan\n",
    "TPD_NEE=np.zeros(np.shape(VPRM_TPD_avg_GPP))*np.nan\n",
    "TPD_NEEgf=np.zeros(np.shape(VPRM_TPD_avg_GPP))*np.nan\n",
    "TPD_R=np.zeros(np.shape(VPRM_TPD_avg_GPP))*np.nan\n",
    "for i in range(np.int(len(TPD_dates)/2)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        if i<8755:\n",
    "            TPD_GPP[i+5]=np.nanmean([TPD_GPPgf_fluxes[i*2],TPD_GPPgf_fluxes[i*2+1]])\n",
    "            TPD_NEE[i+5]=np.nanmean([TPD_NEE_fluxes[i*2],TPD_NEE_fluxes[i*2+1]])\n",
    "            TPD_NEEgf[i+5]=np.nanmean([TPD_NEEgf_fluxes[i*2],TPD_NEEgf_fluxes[i*2+1]])\n",
    "            TPD_R[i+5]=np.nanmean([TPD_Rgf_fluxes[i*2],TPD_Rgf_fluxes[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take daily average of 2018 UrbanVPRM fluxes over TPD\n",
    "\n",
    "VPRM_TPD_daily_NEE=np.zeros(365)*np.nan\n",
    "VPRM_TPD_daily_GPP=np.zeros(365)*np.nan\n",
    "VPRM_TPD_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "Updated_VPRM_TPD_daily_NEE=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TPD_daily_GPP=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TPD_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "date=0\n",
    "daily_NEE_VPRM=[]\n",
    "daily_GPP_VPRM=[]\n",
    "daily_R_VPRM=[]\n",
    "\n",
    "daily_NEE_Updated_VPRM=[]\n",
    "daily_GPP_Updated_VPRM=[]\n",
    "daily_R_Updated_VPRM=[]\n",
    "for i in range(len(VPRM_TPD_avg_DoY)):\n",
    "    if VPRM_TPD_avg_DoY[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_VPRM.append(VPRM_TPD_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TPD_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TPD_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TPD_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TPD_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TPD_avg_Reco[i])\n",
    "            if i==len(VPRM_TPD_avg_DoY)-1:\n",
    "                VPRM_TPD_daily_NEE[date]=np.nanmean(daily_NEE_VPRM)\n",
    "                VPRM_TPD_daily_GPP[date]=np.nanmean(daily_GPP_VPRM)\n",
    "                VPRM_TPD_daily_R[date]=np.nanmean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TPD_daily_NEE[date]=np.nanmean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_daily_GPP[date]=np.nanmean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_daily_R[date]=np.nanmean(daily_R_Updated_VPRM)\n",
    "                \n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_VPRM.append(VPRM_TPD_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TPD_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TPD_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TPD_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TPD_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TPD_avg_Reco[i])\n",
    "            if np.floor(np.round(VPRM_TPD_avg_DoY[i],4))<np.floor(np.round(VPRM_TPD_avg_DoY[i+1],4)):\n",
    "                VPRM_TPD_daily_NEE[date]=np.nanmean(daily_NEE_VPRM)\n",
    "                VPRM_TPD_daily_GPP[date]=np.nanmean(daily_GPP_VPRM)\n",
    "                VPRM_TPD_daily_R[date]=np.nanmean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TPD_daily_NEE[date]=np.nanmean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_daily_GPP[date]=np.nanmean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_daily_R[date]=np.nanmean(daily_R_Updated_VPRM)\n",
    "                \n",
    "                date+=1\n",
    "                daily_NEE_VPRM=[]\n",
    "                daily_GPP_VPRM=[]\n",
    "                daily_R_VPRM=[]\n",
    "                \n",
    "                daily_NEE_Updated_VPRM=[]\n",
    "                daily_GPP_Updated_VPRM=[]\n",
    "                daily_R_Updated_VPRM=[]\n",
    "                \n",
    "# Take daily average of TPD 2018 flux tower data\n",
    "TPD_daily_mean_NEE=np.zeros(365)*np.nan\n",
    "TPD_daily_mean_GPP=np.zeros(365)*np.nan\n",
    "TPD_daily_mean_R=np.zeros(365)*np.nan\n",
    "TPD_daily_mean_NEEgf=np.zeros(365)*np.nan\n",
    "\n",
    "for i in range(len(days_of_year)):\n",
    "    daily_NEEgf_TPD_2018=TPD_NEEgf[np.floor(np.round(VPRM_TPD_avg_DoY,4))==i+1]\n",
    "    daily_NEE_TPD_2018=TPD_NEE[np.floor(np.round(VPRM_TPD_avg_DoY,4))==i+1]\n",
    "    daily_GPP_TPD_2018=TPD_GPP[np.floor(np.round(VPRM_TPD_avg_DoY,4))==i+1]\n",
    "    daily_R_TPD_2018=TPD_R[np.floor(np.round(VPRM_TPD_avg_DoY,4))==i+1]\n",
    "    if len(daily_NEE_TPD_2018)==24:\n",
    "        TPD_daily_mean_NEEgf[i]=np.mean(daily_NEEgf_TPD_2018)\n",
    "        TPD_daily_mean_NEE[i]=np.mean(daily_NEE_TPD_2018)\n",
    "        TPD_daily_mean_GPP[i]=np.mean(daily_GPP_TPD_2018)\n",
    "        TPD_daily_mean_R[i]=np.mean(daily_R_TPD_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in UrbanVPRM 2019 data over TPD\n",
    "\n",
    "#*** CHANGE PATHS & FILENAMES ***\n",
    "VPRM_data=pd.read_csv('TPD_500m_V061_no_adjustments_2019/vprm_mixed_ISA_TPD_500m_V061_2019_no_adjustments.csv')\n",
    "Updated_VPRM_data=pd.read_csv('TPD_V061_500m_2019/vprm_GMIS_Toronto_ACI_SOLRIS_ISA_500m_TPD_V061_2019_no_PScale_adjusted_Topt_Ra_URB_parameters_fixed_gapfilled_LSWI_filtered.csv')\n",
    "\n",
    "VPRM_HoY0=np.zeros([8760,9])*np.nan\n",
    "VPRM_Index0=np.zeros([8760,9])*np.nan\n",
    "VPRM_GEE0=np.zeros([8760,9])*np.nan\n",
    "VPRM_Reco0=np.zeros([8760,9])*np.nan\n",
    "\n",
    "Updated_VPRM_HoY0=np.zeros([8760,9])*np.nan\n",
    "Updated_VPRM_Index0=np.zeros([8760,9])*np.nan\n",
    "Updated_VPRM_GEE0=np.zeros([8760,9])*np.nan\n",
    "Updated_VPRM_Reco0=np.zeros([8760,9])*np.nan\n",
    "h=0\n",
    "l=0\n",
    "for i in range(8760*103,8760*106): #*** NOTE: if you changed the extent in UrbanVPRM you will need to change these indices ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*119,8760*122): #*** NOTE: if you changed the extent in UrbanVPRM you will need to change these indices ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "for i in range(8760*135,8760*138): #*** NOTE: if you changed the extent in UrbanVPRM you will need to change these indices ***\n",
    "    VPRM_HoY0[h,l]=VPRM_data.iat[i,1]\n",
    "    VPRM_Index0[h,l]=VPRM_data.iat[i,2]\n",
    "    VPRM_GEE0[h,l]=VPRM_data.iat[i,3]\n",
    "    VPRM_Reco0[h,l]=VPRM_data.iat[i,9]\n",
    "    \n",
    "    Updated_VPRM_HoY0[h,l]=Updated_VPRM_data.iat[i,1]\n",
    "    Updated_VPRM_Index0[h,l]=Updated_VPRM_data.iat[i,2]\n",
    "    Updated_VPRM_GEE0[h,l]=Updated_VPRM_data.iat[i,3]\n",
    "    Updated_VPRM_Reco0[h,l]=Updated_VPRM_data.iat[i,9]\n",
    "    h+=1\n",
    "    if VPRM_data.iat[i+1,2]>VPRM_data.iat[i,2]:\n",
    "        l+=1\n",
    "        h=0\n",
    "        \n",
    "#Average data falling within TPD footprint\n",
    "\n",
    "#Original UrbanVPRM\n",
    "VPRM_GEE0=VPRM_GEE0\n",
    "VPRM_TPD_2019_avg_DoY=np.nanmean(VPRM_HoY0, axis=1)/24+23/24 #convert from hour 1 to DoY=1\n",
    "VPRM_TPD_2019_avg_Index=np.nanmean(VPRM_Index0, axis=1)\n",
    "VPRM_TPD_2019_avg_GPP=np.nanmean(VPRM_GEE0, axis=1)\n",
    "VPRM_TPD_2019_avg_Reco=np.nanmean(VPRM_Reco0, axis=1)\n",
    "VPRM_TPD_2019_avg_NEE=np.nanmean(VPRM_Reco0-VPRM_GEE0, axis=1)\n",
    "\n",
    "#Updated UrbanVPRM \n",
    "Updated_VPRM_TPD_2019_avg_DoY=np.nanmean(Updated_VPRM_HoY0, axis=1)/24+23/24 #convert from hour 1 to DoY=1\n",
    "Updated_VPRM_TPD_2019_avg_Index=np.nanmean(Updated_VPRM_Index0, axis=1)\n",
    "Updated_VPRM_TPD_2019_avg_GPP=-np.nanmean(Updated_VPRM_GEE0, axis=1)\n",
    "Updated_VPRM_TPD_2019_avg_Reco=np.nanmean(Updated_VPRM_Reco0, axis=1)\n",
    "Updated_VPRM_TPD_2019_avg_NEE=np.nanmean(Updated_VPRM_Reco0+Updated_VPRM_GEE0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in TPD 2019 flux tower fluxes\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "TPD_2019_Fluxes=pd.read_csv('/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TPD_HH_2019.csv', usecols=(0,2,74,75,76))\n",
    "\n",
    "TPD_2019_dates=np.zeros([17520])*np.nan\n",
    "TPD_2019_NEEgf_fluxes=np.zeros([17520])*np.nan\n",
    "TPD_2019_NEE_fluxes=np.zeros([17520])*np.nan\n",
    "TPD_2019_Rgf_fluxes=np.zeros([17520])*np.nan\n",
    "TPD_2019_GPPgf_fluxes=np.zeros([17520])*np.nan\n",
    "\n",
    "for i in range(0,17520):\n",
    "    if 201901010000<=TPD_2019_Fluxes.iat[i,0]<202001010000:\n",
    "        #TP is 5 hours behind UTC #adjust to UTC\n",
    "        TPD_2019_dates[i]=datetime.strptime(str(int(TPD_2019_Fluxes.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TPD_2019_Fluxes.iat[i,0])[8:10])+float(str(TPD_2019_Fluxes.iat[i,0])[10:12])/60)/24+5/24\n",
    "\n",
    "        if TPD_2019_Fluxes.iat[i,4]>-9999:\n",
    "            TPD_2019_NEEgf_fluxes[i]=TPD_2019_Fluxes.iat[i,4] #NEE (gap filled)\n",
    "        if TPD_2019_Fluxes.iat[i,1]>-9999:\n",
    "            TPD_2019_NEE_fluxes[i]=TPD_2019_Fluxes.iat[i,1]\n",
    "        if TPD_2019_Fluxes.iat[i,3]>-9999:\n",
    "            TPD_2019_Rgf_fluxes[i]=TPD_2019_Fluxes.iat[i,3]\n",
    "        if TPD_2019_Fluxes.iat[i,2]>-9999:\n",
    "            TPD_2019_GPPgf_fluxes[i]=TPD_2019_Fluxes.iat[i,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the hourly average of TPD 2019 flux tower data\n",
    "\n",
    "TPD_2019_GPP=np.zeros(np.shape(VPRM_TPD_2019_avg_GPP))*np.nan\n",
    "TPD_2019_NEE=np.zeros(np.shape(VPRM_TPD_2019_avg_GPP))*np.nan\n",
    "TPD_2019_NEEgf=np.zeros(np.shape(VPRM_TPD_2019_avg_GPP))*np.nan\n",
    "TPD_2019_R=np.zeros(np.shape(VPRM_TPD_2019_avg_GPP))*np.nan\n",
    "for i in range(np.int(len(TPD_2019_dates)/2)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        if i<8755:\n",
    "            TPD_2019_GPP[i+5]=np.nanmean([TPD_2019_GPPgf_fluxes[i*2],TPD_2019_GPPgf_fluxes[i*2+1]])\n",
    "            TPD_2019_NEE[i+5]=np.nanmean([TPD_2019_NEE_fluxes[i*2],TPD_2019_NEE_fluxes[i*2+1]])\n",
    "            TPD_2019_NEEgf[i+5]=np.nanmean([TPD_2019_NEEgf_fluxes[i*2],TPD_2019_NEEgf_fluxes[i*2+1]])\n",
    "            TPD_2019_R[i+5]=np.nanmean([TPD_2019_Rgf_fluxes[i*2],TPD_2019_Rgf_fluxes[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the daily average of UrbanVPRM 2019 data over TPD\n",
    "VPRM_TPD_2019_daily_NEE=np.zeros(365)*np.nan\n",
    "VPRM_TPD_2019_daily_GPP=np.zeros(365)*np.nan\n",
    "VPRM_TPD_2019_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "Updated_VPRM_TPD_2019_daily_NEE=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TPD_2019_daily_GPP=np.zeros(365)*np.nan\n",
    "Updated_VPRM_TPD_2019_daily_R=np.zeros(365)*np.nan\n",
    "\n",
    "date=0\n",
    "daily_NEE_VPRM=[]\n",
    "daily_GPP_VPRM=[]\n",
    "daily_R_VPRM=[]\n",
    "\n",
    "daily_NEE_Updated_VPRM=[]\n",
    "daily_GPP_Updated_VPRM=[]\n",
    "daily_R_Updated_VPRM=[]\n",
    "for i in range(len(VPRM_TPD_2019_avg_DoY)):\n",
    "    if VPRM_TPD_2019_avg_DoY[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_VPRM.append(VPRM_TPD_2019_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TPD_2019_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TPD_2019_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TPD_2019_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TPD_2019_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TPD_2019_avg_Reco[i])\n",
    "            if i==len(VPRM_TPD_2019_avg_DoY)-1:\n",
    "                VPRM_TPD_2019_daily_NEE[date]=np.nanmean(daily_NEE_VPRM)\n",
    "                VPRM_TPD_2019_daily_GPP[date]=np.nanmean(daily_GPP_VPRM)\n",
    "                VPRM_TPD_2019_daily_R[date]=np.nanmean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TPD_2019_daily_NEE[date]=np.nanmean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_2019_daily_GPP[date]=np.nanmean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_2019_daily_R[date]=np.nanmean(daily_R_Updated_VPRM)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_VPRM.append(VPRM_TPD_2019_avg_NEE[i])\n",
    "            daily_GPP_VPRM.append(VPRM_TPD_2019_avg_GPP[i])\n",
    "            daily_R_VPRM.append(VPRM_TPD_2019_avg_Reco[i])\n",
    "            \n",
    "            daily_NEE_Updated_VPRM.append(Updated_VPRM_TPD_2019_avg_NEE[i])\n",
    "            daily_GPP_Updated_VPRM.append(Updated_VPRM_TPD_2019_avg_GPP[i])\n",
    "            daily_R_Updated_VPRM.append(Updated_VPRM_TPD_2019_avg_Reco[i])\n",
    "            if np.floor(np.round(VPRM_TPD_2019_avg_DoY[i],4))<np.floor(np.round(VPRM_TPD_2019_avg_DoY[i+1],4)):\n",
    "                VPRM_TPD_2019_daily_NEE[date]=np.nanmean(daily_NEE_VPRM)\n",
    "                VPRM_TPD_2019_daily_GPP[date]=np.nanmean(daily_GPP_VPRM)\n",
    "                VPRM_TPD_2019_daily_R[date]=np.nanmean(daily_R_VPRM)\n",
    "                \n",
    "                Updated_VPRM_TPD_2019_daily_NEE[date]=np.nanmean(daily_NEE_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_2019_daily_GPP[date]=np.nanmean(daily_GPP_Updated_VPRM)\n",
    "                Updated_VPRM_TPD_2019_daily_R[date]=np.nanmean(daily_R_Updated_VPRM)\n",
    "                                \n",
    "                date+=1\n",
    "                daily_NEE_VPRM=[]\n",
    "                daily_GPP_VPRM=[]\n",
    "                daily_R_VPRM=[]\n",
    "                \n",
    "                daily_NEE_Updated_VPRM=[]\n",
    "                daily_GPP_Updated_VPRM=[]\n",
    "                daily_R_Updated_VPRM=[]\n",
    "\n",
    "\n",
    "# Take the daily average of TPD 2019 flux tower data                \n",
    "TPD_2019_daily_mean_NEE=np.zeros(365)*np.nan\n",
    "TPD_2019_daily_mean_GPP=np.zeros(365)*np.nan\n",
    "TPD_2019_daily_mean_R=np.zeros(365)*np.nan\n",
    "TPD_2019_daily_mean_NEEgf=np.zeros(365)*np.nan\n",
    "\n",
    "for i in range(len(days_of_year)):\n",
    "    daily_NEEgf_TPD_2019=TPD_2019_NEEgf[np.floor(np.round(VPRM_TPD_2019_avg_DoY,4))==i+1]\n",
    "    daily_NEE_TPD_2019=TPD_2019_NEE[np.floor(np.round(VPRM_TPD_2019_avg_DoY,4))==i+1]\n",
    "    daily_GPP_TPD_2019=TPD_2019_GPP[np.floor(np.round(VPRM_TPD_2019_avg_DoY,4))==i+1]\n",
    "    daily_R_TPD_2019=TPD_2019_R[np.floor(np.round(VPRM_TPD_2019_avg_DoY,4))==i+1]\n",
    "    if len(daily_NEE_TPD_2019)==24:\n",
    "        TPD_2019_daily_mean_NEEgf[i]=np.mean(daily_NEEgf_TPD_2019)\n",
    "        TPD_2019_daily_mean_NEE[i]=np.mean(daily_NEE_TPD_2019)\n",
    "        TPD_2019_daily_mean_GPP[i]=np.mean(daily_GPP_TPD_2019)\n",
    "        TPD_2019_daily_mean_R[i]=np.mean(daily_R_TPD_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data from all sites\n",
    "All_VPRM_NEE=np.concatenate([VPRM_Borden_2018_avg_NEE,VPRM_TP39_2018_avg_NEE,VPRM_TPD_avg_NEE,VPRM_TP39_2019_avg_NEE,VPRM_TPD_2019_avg_NEE])\n",
    "All_Updated_VPRM_NEE=np.concatenate([Updated_VPRM_Borden_2018_avg_NEE,Updated_VPRM_TP39_2018_avg_NEE,Updated_VPRM_TPD_avg_NEE,Updated_VPRM_TP39_2019_avg_NEE,Updated_VPRM_TPD_2019_avg_NEE])\n",
    "\n",
    "All_fluxtower_NEE=np.concatenate([Borden_NEE,TP39_NEE,TPD_NEE,TP39_2019_NEE,TPD_2019_NEE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finitemask1 = np.isfinite(All_fluxtower_NEE)\n",
    "All_fluxtower_NEEclean0 = All_fluxtower_NEE[finitemask1]\n",
    "All_VPRM_NEEclean0 = All_VPRM_NEE[finitemask1]\n",
    "All_Updated_VPRM_NEEclean0 = All_Updated_VPRM_NEE[finitemask1]\n",
    "\n",
    "finitemask2 = np.isfinite(All_VPRM_NEEclean0)\n",
    "Total_fluxtower_VPRM_NEE =  All_fluxtower_NEEclean0[finitemask2]\n",
    "Total_VPRM_NEE = All_VPRM_NEEclean0[finitemask2]\n",
    "\n",
    "finitemask3 = np.isfinite(All_Updated_VPRM_NEEclean0)\n",
    "Total_fluxtower_Updated_VPRM_NEE = All_fluxtower_NEEclean0[finitemask3]\n",
    "Total_Updated_VPRM_NEE = All_Updated_VPRM_NEEclean0[finitemask3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the original UrbanVPRM NEE to flux tower (non-gapfilled) NEE using a bootstrapped Huber fit\n",
    "\n",
    "Huber_Tot_NEE_slps=[]\n",
    "Huber_Tot_NEE_ints=[]\n",
    "Huber_Tot_NEE_R2=[]\n",
    "\n",
    "#try bootstrapping 1000 times\n",
    "indx_list=list(range(0,len(Total_VPRM_NEE)))\n",
    "for i in range(1,1001):\n",
    "    #sub selection of points\n",
    "    NEE_indx=np.random.choice(indx_list,size=len(Total_VPRM_NEE))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((Total_fluxtower_VPRM_NEE[NEE_indx]).reshape(-1,1),Total_VPRM_NEE[NEE_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = Total_fluxtower_VPRM_NEE, Total_VPRM_NEE\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_Tot_NEE_slps.append(H_m)\n",
    "        Huber_Tot_NEE_ints.append(H_c)\n",
    "        Huber_Tot_NEE_R2.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    \n",
    "Huber_Tot_R2 = r2_score(Total_VPRM_NEE, Total_fluxtower_VPRM_NEE*np.nanmean(Huber_Tot_NEE_slps)+np.nanmean(Huber_Tot_NEE_ints))\n",
    "\n",
    "print('Original VPRM slope: '+str(np.round(np.nanmean(Huber_Tot_NEE_slps),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_NEE_slps),3)))\n",
    "print('Original VPRM intercept: '+str(np.round(np.nanmean(Huber_Tot_NEE_ints),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_NEE_ints),3)))\n",
    "\n",
    "print('Original VPRM R^2: '+str(np.round(Huber_Tot_R2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the updated UrbanVPRM NEE to flux tower (non-gapfilled) NEE using a bootstrapped Huber fit\n",
    "\n",
    "#Correct flux tower NEE & average after\n",
    "Huber_Tot_Updated_NEE_slps=[]\n",
    "Huber_Tot_Updated_NEE_ints=[]\n",
    "Huber_Tot_Updated_NEE_R2=[]\n",
    "\n",
    "#try bootstrapping 1000 times\n",
    "indx_list=list(range(0,len(Total_Updated_VPRM_NEE)))\n",
    "for i in range(1,1001):\n",
    "    #sub selection of points\n",
    "    NEE_indx=np.random.choice(indx_list,size=len(Total_Updated_VPRM_NEE))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((Total_fluxtower_Updated_VPRM_NEE[NEE_indx]).reshape(-1,1),Total_Updated_VPRM_NEE[NEE_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = Total_fluxtower_Updated_VPRM_NEE, Total_Updated_VPRM_NEE\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_Tot_Updated_NEE_slps.append(H_m)\n",
    "        Huber_Tot_Updated_NEE_ints.append(H_c)\n",
    "        Huber_Tot_Updated_NEE_R2.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    \n",
    "Huber_Tot_Updated_R2 = r2_score(Total_Updated_VPRM_NEE, Total_fluxtower_Updated_VPRM_NEE*np.nanmean(Huber_Tot_Updated_NEE_slps)+np.nanmean(Huber_Tot_Updated_NEE_ints))\n",
    "\n",
    "print('Updated VPRM slope: '+str(np.round(np.nanmean(Huber_Tot_Updated_NEE_slps),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_Updated_NEE_slps),3)))\n",
    "print('Updated VPRM intercept: '+str(np.round(np.nanmean(Huber_Tot_Updated_NEE_ints),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_Updated_NEE_ints),3)))\n",
    "\n",
    "print('Updated VPRM R^2: '+str(np.round(Huber_Tot_Updated_R2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('tableau-colorblind10')\n",
    "plt.rc('font',size=18)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlim(-80,20)\n",
    "plt.ylim(-80,20)\n",
    "plt.axis('scaled')\n",
    "\n",
    "plt.scatter(-100,-100,label='Original UrbanVPRM')\n",
    "plt.scatter(-100,-100,label='Updated UrbanVPRM')\n",
    "plt.scatter(Total_fluxtower_VPRM_NEE,Total_VPRM_NEE,s=5,c='#006BA4')\n",
    "plt.scatter(Total_fluxtower_Updated_VPRM_NEE,Total_Updated_VPRM_NEE,s=5,c='#FF800E',alpha=0.5)\n",
    "\n",
    "plt.plot(line1_1,func2(line1_1,np.nanmean(Huber_Tot_NEE_slps),np.nanmean(Huber_Tot_NEE_ints)),linestyle='--',label=str(np.round(np.nanmean(Huber_Tot_NEE_slps),2))+'$\\cdot$x+'+str(np.round(np.nanmean(Huber_Tot_NEE_ints),2))+', R$^2$ = '+str(np.round(np.nanmean(Huber_Tot_R2),2)),c='k', path_effects=[pe.Stroke(linewidth=5, foreground='#006BA4'), pe.Normal()])\n",
    "plt.plot(line1_1,func2(line1_1,np.nanmean(Huber_Tot_Updated_NEE_slps),np.nanmean(Huber_Tot_Updated_NEE_ints)),linestyle='-.',label=str(np.round(np.nanmean(Huber_Tot_Updated_NEE_slps),2))+'$\\cdot$x+'+str(np.round(np.nanmean(Huber_Tot_Updated_NEE_ints),2))+', R$^2$ = '+str(np.round(Huber_Tot_Updated_R2,2)),c='k', path_effects=[pe.Stroke(linewidth=5, foreground='#FF800E'), pe.Normal()])\n",
    "\n",
    "plt.plot(line1_1,line1_1,linestyle=':',c='k')\n",
    "plt.title('UrbanVPRM vs Flux Tower NEE')\n",
    "plt.xlabel('Flux Tower NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "plt.ylabel('Modelled NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "plt.legend()\n",
    "# *** Uncomment to save figure as pdf and as png. CHANGE PATHS & FILENAMES *** (part of Fig 2)\n",
    "#plt.savefig('UrbanVPRM_V061_vs_fixed_fluxtower_non_gapfilled_NEE_hrly_Huber_fit_correlation_All_fluxes_2018_2019_larger_font_cb_friendly.pdf',bbox_inches='tight')\n",
    "#plt.savefig('UrbanVPRM_V061_vs_fixed_fluxtower_non_gapfilled_NEE_hrly_Huber_fit_correlation_All_fluxes_2018_2019_larger_font_cb_friendly.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font',size=22)\n",
    "\n",
    "fig, ax = plt.subplots(3,3,sharex=True,figsize=(11,8))\n",
    "ax[0,0].set_xlim(1,365)\n",
    "ax[0,0].set_ylim(-2,22)\n",
    "ax[0,1].set_ylim(-2,22)\n",
    "ax[0,2].set_ylim(-2,22)\n",
    "\n",
    "l0,=ax[0,0].plot(days_of_year,Borden_daily_mean_GPPgf+50,label='Borden Fluxtower',c='k')\n",
    "ax[0,0].plot(days_of_year,Borden_daily_mean_GPPgf,label='Borden 2018-2020',c='k')\n",
    "\n",
    "ls0,=ax[0,0].plot(days_of_year,days_of_year+50,label='Original VPRM',c='#006BA4')\n",
    "ax[0,0].plot(days_of_year,VPRM_daily_GPP_Borden_2018,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "\n",
    "ls1,=ax[0,0].plot(days_of_year,days_of_year+50,label='Updated VPRM',c='#FF800E',linestyle='--')\n",
    "ax[0,0].plot(days_of_year,Updated_VPRM_daily_GPP_Borden_2018,label='Updated VPRM',c='#FF800E', alpha=0.75,linestyle='--')\n",
    "ax[0,0].set_title('GPP')\n",
    "\n",
    "l1=ax[0,1].scatter(days_of_year,TP39_daily_mean_GPP+50,label='TP39 Fluxtower',c='k')\n",
    "ax[0,1].plot(days_of_year,TP39_daily_mean_GPP,label='TP39 2018-2019',c='k')\n",
    "\n",
    "ax[0,1].plot(days_of_year,VPRM_TP39_2018_daily_GPP,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "\n",
    "ax[0,1].plot(days_of_year,Updated_VPRM_TP39_2018_daily_GPP,label='Original VPRM',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "ax[0,0].set_ylabel('GPP')\n",
    "\n",
    "l2=ax[0,2].scatter(days_of_year,TPD_daily_mean_GPP+50,label='TPD Fluxtower',c='k')\n",
    "ax[0,2].plot(days_of_year,TPD_daily_mean_GPP,label='TPD 2018-2019',c='k')\n",
    "ax[0,2].plot(days_of_year,VPRM_TPD_daily_GPP,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[0,2].plot(days_of_year,Updated_VPRM_TPD_daily_GPP,label='Updated VPRM',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[1,0].set_ylim(-1,22)\n",
    "ax[1,1].set_ylim(-1,22)\n",
    "ax[1,2].set_ylim(-1,22)\n",
    "\n",
    "ax[1,0].plot(days_of_year,Borden_daily_mean_Rgf,label='Borden 2018-2020',c='k')\n",
    "ax[1,0].plot(days_of_year,VPRM_daily_R_Borden_2018,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[1,0].plot(days_of_year,Updated_VPRM_daily_R_Borden_2018,label='Updated VPRM',c='#FF800E', alpha=0.75,linestyle='--')\n",
    "ax[0,0].set_title('GPP')\n",
    "\n",
    "ax[1,1].plot(days_of_year,TP39_daily_mean_R,label='TP39 2018-2019',c='k')\n",
    "ax[1,1].plot(days_of_year,VPRM_TP39_2018_daily_R,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[1,1].plot(days_of_year,Updated_VPRM_TP39_2018_daily_R,label='Original VPRM',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "l2=ax[1,2].scatter(days_of_year,TPD_daily_mean_R+50,label='TPD Fluxtower',c='k')\n",
    "ax[1,2].plot(days_of_year,TPD_daily_mean_R,label='TPD 2018-2019',c='k')\n",
    "ax[1,2].plot(days_of_year,VPRM_TPD_daily_R,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[1,2].plot(days_of_year,Updated_VPRM_TPD_daily_R,label='Updated VPRM',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[1,0].set_ylabel('R$_{eco}$')\n",
    "\n",
    "ax[2,0].set_ylim(-16,6)\n",
    "ax[2,1].set_ylim(-16,6)\n",
    "ax[2,2].set_ylim(-16,6)\n",
    "\n",
    "ax[2,0].plot(days_of_year,Borden_daily_mean_NEEgf,label='Borden 2018-2020',c='k')\n",
    "ax[2,0].plot(days_of_year,VPRM_daily_NEE_Borden_2018,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[2,0].plot(days_of_year,Updated_VPRM_daily_NEE_Borden_2018,label='Updated VPRM',c='#FF800E', alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[0,0].set_title('Borden Forest')\n",
    "ax[0,1].set_title('TP39')\n",
    "ax[0,2].set_title('TPD')\n",
    "\n",
    "ax[2,1].plot(days_of_year,TP39_daily_mean_NEEgf,label='TP39 2018-2019',c='k')\n",
    "ax[2,1].plot(days_of_year,VPRM_TP39_2018_daily_NEE,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[2,1].plot(days_of_year,Updated_VPRM_TP39_2018_daily_NEE,label='Original VPRM',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[2,2].plot(days_of_year,TPD_daily_mean_NEEgf,label='TPD 2018-2019',c='k')\n",
    "ax[2,2].plot(days_of_year,VPRM_TPD_daily_NEE,label='Original VPRM',c='#006BA4',alpha=0.75)\n",
    "ax[2,2].plot(days_of_year,Updated_VPRM_TPD_daily_NEE,label='Updated VPRM',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[2,0].set_ylabel('NEE')\n",
    "\n",
    "ax[0,1].set_yticks([])\n",
    "ax[0,2].set_yticks([])\n",
    "ax[1,1].set_yticks([])\n",
    "ax[1,2].set_yticks([])\n",
    "ax[2,1].set_yticks([])\n",
    "ax[2,2].set_yticks([])\n",
    "\n",
    "ax[1,0].legend([l0,ls0,ls1],['Flux Tower','Original VPRM','Updated VPRM'],loc='upper left',fontsize=16)\n",
    "ax[2,1].set_xlabel('Day of Year')\n",
    "fig.subplots_adjust(hspace=0,wspace=0)\n",
    "# *** Uncomment next two lines to save figure as pdf and png. CHANGE PATHS & FILENAMES *** (part of fig 2)\n",
    "#plt.savefig('UrbanVPRM_V061_vs_fixed_fluxtower_Comparison_All_fluxes_2018_larger_font_cb_friendly.pdf',bbox_inches='tight')\n",
    "#plt.savefig('UrbanVPRM_V061_vs_fixed_fluxtower_Comparison_All_fluxes_2018_larger_font_cb_friendly.png',bbox_inches='tight')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
