{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code compares biogenic fluxes estimated by the Original and Updated SMUrF models to those\n",
    "# estimated by three eddy-covariance flux towers in Southern Ontario: Borden Forest Mixed Deciduous,\n",
    "# Turkey Point 1939 Pine (TP39), and Turkey Point Deciduous (TPD). \n",
    "\n",
    "# The code loads in the data\n",
    "# It then generates timeseries of daily-averaged flux tower & SMUrF (original and updated) NEE, GPP & Reco,\n",
    "\n",
    "# The code also applies bootstrapped Huber fits to the hourly NEE fluxes estimated by SMUrF and the \n",
    "# non-gapfilled NEE from all 3 flux towers, for both the original and modified SMUrF\n",
    "\n",
    "# This code generates figures 2 c & d of Madsen-Colford et al. 2025\n",
    "\n",
    "# Comments including '***' indicate parts of the code that may need to be changed by the user (e.g. path/filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numerical python\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from matplotlib.cm import get_cmap #import colour maps for contour plots\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset, date2num #for reading netCDF data files and their date (not sure if I need the later)\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import optimize as opt \n",
    "from scipy import odr\n",
    "from datetime import datetime, timedelta\n",
    "#from datetime import datetime as dt\n",
    "import matplotlib.patheffects as pe\n",
    "from sklearn import linear_model #for robust fitting\n",
    "from sklearn.metrics import r2_score, mean_squared_error #for analyzing robust fits\n",
    "import matplotlib.colors as clrs #for log color scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the first Reco file to extract the start time of 2018, in seconds since 1970, & convert to days since 1970\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "g=Dataset('E:/Research/SMUrF/output2018_CSIF_V061/easternCONUS/daily_mean_Reco_neuralnet/era5/2018/daily_mean_Reco_uncert_easternCONUS_20180101.nc')\n",
    "start_of_year=g.variables['time'][0]/3600/24-1 #convert seconds since 1970 to days (minus one)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the original SMUrF fluxes\n",
    "\n",
    "# *** CHANGE PATH ***\n",
    "C_path = 'E:/Research/SMUrF/output2018_CSIF_V061/easternCONUS/hourly_flux_era5/'\n",
    "# *** CHANGE FILENAME ***\n",
    "C_fn = 'hrly_mean_GPP_Reco_NEE_easternCONUS_2018' #filename WITHOUT the month\n",
    "\n",
    "C_time=[]\n",
    "C_Reco=[]\n",
    "C_NEE=[]\n",
    "C_GPP=[]\n",
    "C_lats=[]\n",
    "C_lons=[]\n",
    "for j in range(1,13):\n",
    "    try:\n",
    "        if j<10:\n",
    "            f=Dataset(C_path+C_fn+'0'+str(j)+'.nc')\n",
    "        else:\n",
    "            # 2018:\n",
    "            f=Dataset(C_path+C_fn+str(j)+'.nc')\n",
    "        if len(C_time)==0: #if it is the first month, make arrays of data & save lat/lon\n",
    "            C_lats=f.variables['lat'][:]\n",
    "            C_lons=f.variables['lon'][:]\n",
    "            C_Reco=f.variables['Reco_mean'][:]\n",
    "            C_GPP=f.variables['GPP_mean'][:]\n",
    "            C_NEE=f.variables['NEE_mean'][:]\n",
    "            C_time=f.variables['time'][:]/24/3600-start_of_year-5/24 #convert seconds since 1970 to days and subtract start of year and adjust to local time\n",
    "        else: #otherwise append this month's data to the arrays\n",
    "            C_Reco=np.concatenate((C_Reco,f.variables['Reco_mean'][:]),axis=0)\n",
    "            C_GPP=np.concatenate((C_GPP,f.variables['GPP_mean'][:]),axis=0)\n",
    "            C_NEE=np.concatenate((C_NEE,f.variables['NEE_mean'][:]),axis=0)\n",
    "            C_time=np.concatenate((C_time,(f.variables['time'][:]/24/3600-start_of_year-5/24)),axis=0)\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "# Set fill values to NaN\n",
    "C_Reco[C_Reco==-999]=np.nan\n",
    "C_NEE[C_NEE==-999]=np.nan\n",
    "C_GPP[C_GPP==-999]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select original SMUrF pixel that lands over the Borden Forest flux tower\n",
    "C_GPP_array=np.zeros(8765)*np.nan\n",
    "C_NEE_array=np.zeros(8765)*np.nan\n",
    "C_Reco_array=np.zeros(8765)*np.nan\n",
    "C_time_array=np.zeros(8765)*np.nan\n",
    "for i in range(len(C_GPP[:,0,0])):\n",
    "    C_time_array[i]=C_time[i]\n",
    "    C_GPP_array[i]=C_GPP[i,36,15]\n",
    "    C_NEE_array[i]=C_NEE[i,36,15]\n",
    "    C_Reco_array[i]=C_Reco[i,36,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Borden Forest fluxes\n",
    "\n",
    "#*** CHANGE PATH & FILENAME ***\n",
    "Borden_Fluxes=pd.read_csv('/Users/kitty/Documents/Research/SIF/Flux_Tower/2018_NEP_GPP_Borden.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Borden_dates_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_NEEgf_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_NEE_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_Rgf_fluxes=np.zeros([17520])*np.nan\n",
    "Borden_GEPgf_fluxes=np.zeros([17520])*np.nan\n",
    "for i in range(0,17520):\n",
    "    Borden_dates_fluxes[i]=Borden_Fluxes.iat[i,0]-5/24 #adjust to local time\n",
    "    Borden_NEEgf_fluxes[i]=-Borden_Fluxes.iat[i,5] #NEE (gap filled)\n",
    "    Borden_NEE_fluxes[i]=-Borden_Fluxes.iat[i,1] # NEE (non gap-filled)\n",
    "    Borden_Rgf_fluxes[i]=Borden_Fluxes.iat[i,6] #Reco\n",
    "    Borden_GEPgf_fluxes[i]=Borden_Fluxes.iat[i,7] #GPP\n",
    "del Borden_Fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take daily average of fluxtower fluxes\n",
    "days_of_year=np.arange(1,366)+0.5 #Make the day of year centered on the middle of the day (i.e. noon)\n",
    "Borden_daily_NEE=np.zeros(365)*np.nan\n",
    "Borden_daily_NEEgf=np.zeros(365)*np.nan\n",
    "Borden_daily_GPPgf=np.zeros(365)*np.nan\n",
    "Borden_daily_Rgf=np.zeros(365)*np.nan\n",
    "date=0\n",
    "daily_NEE=[]\n",
    "daily_NEEgf=[]\n",
    "daily_GPPgf=[]\n",
    "daily_Rgf=[]\n",
    "for i in range(len(Borden_dates_fluxes)):\n",
    "    if np.round(Borden_dates_fluxes[i],4)>=1:\n",
    "        if np.round(Borden_dates_fluxes[i],4)<365: #The last day is not complete (in local time) so skip it in daily average\n",
    "            # If it is not the last day, append the data to the flux lists\n",
    "            daily_NEE.append(Borden_NEE_fluxes[i])\n",
    "            daily_NEEgf.append(Borden_NEEgf_fluxes[i])\n",
    "            daily_GPPgf.append(Borden_GEPgf_fluxes[i])\n",
    "            daily_Rgf.append(Borden_Rgf_fluxes[i])\n",
    "            #If it is the last hour of the day, average the lists of fluxes and save to an array & empty the list\n",
    "            if np.floor(np.round(Borden_dates_fluxes[i],4))<np.floor(np.round(Borden_dates_fluxes[i+1],4)):\n",
    "                Borden_daily_NEE[date]=np.mean(daily_NEE)\n",
    "\n",
    "                Borden_daily_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                Borden_daily_GPPgf[date]=np.mean(daily_GPPgf)\n",
    "                Borden_daily_Rgf[date]=np.mean(daily_Rgf)\n",
    "\n",
    "                date+=1\n",
    "                daily_NEE=[]\n",
    "                daily_NEEgf=[]\n",
    "                daily_GPPgf=[]\n",
    "                daily_Rgf=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a straight line and a linear function for plotting fits\n",
    "line1_1=np.arange(-100,100)\n",
    "\n",
    "def func2(x,m,b):\n",
    "    return m*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an array for the date & time of year (in decimal day of year)\n",
    "date_array=np.arange(np.nanmin(C_time),366,1/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Original SMUrF to daily resolution\n",
    "\n",
    "C_daily_NEE=np.zeros(365)*np.nan\n",
    "C_daily_GPP=np.zeros(365)*np.nan\n",
    "C_daily_R=np.zeros(365)*np.nan\n",
    "date=0\n",
    "daily_NEE_C=[]\n",
    "daily_GPP_C=[]\n",
    "daily_R_C=[]\n",
    "for i in range(len(date_array)):\n",
    "    if np.round(date_array[i],4)>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_C.append(C_NEE_array[i])\n",
    "            daily_GPP_C.append(C_GPP_array[i])\n",
    "            daily_R_C.append(C_Reco_array[i])\n",
    "            if i==len(date_array)-1:\n",
    "                C_daily_NEE[date]=np.mean(daily_NEE_C)\n",
    "                C_daily_GPP[date]=np.mean(daily_GPP_C)\n",
    "                C_daily_R[date]=np.mean(daily_R_C)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_C.append(C_NEE_array[i])\n",
    "            daily_GPP_C.append(C_GPP_array[i])\n",
    "            daily_R_C.append(C_Reco_array[i])\n",
    "            if np.floor(np.round(date_array[i],4))<np.floor(np.round(date_array[i+1],4)):\n",
    "                C_daily_NEE[date]=np.mean(daily_NEE_C)\n",
    "                C_daily_GPP[date]=np.mean(daily_GPP_C)\n",
    "                C_daily_R[date]=np.mean(daily_R_C)\n",
    "            \n",
    "                date+=1\n",
    "                daily_NEE_C=[]\n",
    "                daily_GPP_C=[]\n",
    "                daily_R_C=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take hourly average of Borden flux tower data (current half-hour and the next half-hour)\n",
    "\n",
    "Borden_NEE=np.zeros(np.shape(C_GPP_array))*np.nan\n",
    "Borden_GEPgf=np.zeros(np.shape(C_GPP_array))*np.nan\n",
    "Borden_NEEgf=np.zeros(np.shape(C_GPP_array))*np.nan\n",
    "Borden_Rgf=np.zeros(np.shape(C_GPP_array))*np.nan\n",
    "\n",
    "for i in range(np.int(len(Borden_dates_fluxes)/2)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        Borden_NEE[i]=np.nanmean([Borden_NEE_fluxes[i*2],Borden_NEE_fluxes[i*2+1]])\n",
    "        Borden_GEPgf[i]=np.nanmean([Borden_GEPgf_fluxes[i*2],Borden_GEPgf_fluxes[i*2+1]])\n",
    "        Borden_NEEgf[i]=np.nanmean([Borden_NEEgf_fluxes[i*2],Borden_NEEgf_fluxes[i*2+1]])\n",
    "        Borden_Rgf[i]=np.nanmean([Borden_Rgf_fluxes[i*2],Borden_Rgf_fluxes[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in original SMUrF fluxes for 2019\n",
    "\n",
    "# load in first Reco file to get the time of the first day of the year (since 1970)\n",
    "g=Dataset('E:/Research/SMUrF/output2019_CSIF_V061/easternCONUS/daily_mean_Reco_neuralnet/era5/2019/daily_mean_Reco_uncert_easternCONUS_20190101.nc')\n",
    "start_of_year_2019=g.variables['time'][0]/3600/24-1 #convert seconds since 1970 to days (minus one)\n",
    "g.close()\n",
    "\n",
    "# *** CHANGE PATH ***\n",
    "C_path = 'E:/Research/SMUrF/output2019_CSIF_V061/easternCONUS/hourly_flux_era5/'\n",
    "# *** CHANGE FILENAME ***\n",
    "C_fn= 'hrly_mean_GPP_Reco_NEE_easternCONUS_2019' # filename without month (added in loop)\n",
    "\n",
    "C_time_2019=[]\n",
    "C_Reco_2019=[]\n",
    "C_NEE_2019=[]\n",
    "C_GPP_2019=[]\n",
    "C_lats_2019=[]\n",
    "C_lons_2019=[]\n",
    "for j in range(1,13):\n",
    "    try:\n",
    "        if j<10:\n",
    "            # 2019:\n",
    "            f=Dataset(C_path+C_fn+'0'+str(j)+'.nc')\n",
    "        else:\n",
    "            # 2019:\n",
    "            f=Dataset(C_path+C_fn+str(j)+'.nc')\n",
    "        if len(C_time_2019)==0: #if it is the first month save the flux data to an arrays\n",
    "            C_lats_2019=f.variables['lat'][:]\n",
    "            C_lons_2019=f.variables['lon'][:]\n",
    "            C_Reco_2019=f.variables['Reco_mean'][:]\n",
    "            C_GPP_2019=f.variables['GPP_mean'][:]\n",
    "            C_NEE_2019=f.variables['NEE_mean'][:]\n",
    "            C_time_2019=f.variables['time'][:]/24/3600-start_of_year_2019-5/24 #convert seconds since 1970 to days and subtract start of year and adjust to local time\n",
    "        else: #otherwise add to the arrays\n",
    "            C_Reco_2019=np.concatenate((C_Reco_2019,f.variables['Reco_mean'][:]),axis=0)\n",
    "            C_GPP_2019=np.concatenate((C_GPP_2019,f.variables['GPP_mean'][:]),axis=0)\n",
    "            C_NEE_2019=np.concatenate((C_NEE_2019,f.variables['NEE_mean'][:]),axis=0)\n",
    "            C_time_2019=np.concatenate((C_time_2019,(f.variables['time'][:]/24/3600-start_of_year_2019-5/24)),axis=0)\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "# Replace fill values with NaN\n",
    "C_Reco_2019[C_Reco_2019==-999]=np.nan\n",
    "C_NEE_2019[C_NEE_2019==-999]=np.nan\n",
    "C_GPP_2019[C_GPP_2019==-999]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same for TP39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in TP39 2018 flux tower data\n",
    "\n",
    "TP39_2018_data=pd.read_csv('C:/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TP39_HH_2018.csv', usecols=[0,1,2,77,78,79]) #header=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP39_2018_dates=np.zeros([17520])*np.nan\n",
    "TP39_2018_NEE=np.zeros([17520])*np.nan\n",
    "TP39_2018_NEE2=np.zeros([17520])*np.nan\n",
    "TP39_2018_GPP=np.zeros([17520])*np.nan\n",
    "TP39_2018_R=np.zeros([17520])*np.nan\n",
    "for i in range(17520):\n",
    "    if 201801010000<=TP39_2018_data.iat[i,0]<201901010000:\n",
    "        TP39_2018_dates[i]=datetime.strptime(str(int(TP39_2018_data.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TP39_2018_data.iat[i,0])[8:10])+float(str(TP39_2018_data.iat[i,0])[10:12])/60)/24\n",
    "        #check that the value is greater than -9999 (value for empty measurements)\n",
    "        if TP39_2018_data.iat[i,2]>-9999:\n",
    "            TP39_2018_NEE2[i]=TP39_2018_data.iat[i,2] # save the NEE (non-gapfilled) data\n",
    "        if TP39_2018_data.iat[i,5]>-9999:\n",
    "            TP39_2018_NEE[i]=TP39_2018_data.iat[i,5] # save the NEE (gap-filled) \n",
    "        if TP39_2018_data.iat[i,3]>-9999:\n",
    "            TP39_2018_GPP[i]=TP39_2018_data.iat[i,3] # save the GPP\n",
    "        if TP39_2018_data.iat[i,4]>-9999:\n",
    "            TP39_2018_R[i]=TP39_2018_data.iat[i,4] # save the Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Original SMUrF pixel over TP39 flux tower\n",
    "C_GPP_TP39_array=np.zeros(8765)*np.nan\n",
    "C_NEE_TP39_array=np.zeros(8765)*np.nan\n",
    "C_Reco_TP39_array=np.zeros(8765)*np.nan\n",
    "\n",
    "for i in range(len(C_GPP[:,0,0])):\n",
    "    C_GPP_TP39_array[i]=C_GPP[i,4,6]\n",
    "    C_NEE_TP39_array[i]=C_NEE[i,4,6]\n",
    "    C_Reco_TP39_array[i]=C_Reco[i,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the daily average of TP39 flux tower data\n",
    "\n",
    "days_of_year=np.arange(1,366)+0.5\n",
    "TP39_daily_NEE=np.zeros(365)*np.nan\n",
    "TP39_daily_NEEgf=np.zeros(365)*np.nan\n",
    "TP39_daily_GPP=np.zeros(365)*np.nan\n",
    "TP39_daily_R=np.zeros(365)*np.nan\n",
    "date=0\n",
    "daily_NEE=[]\n",
    "daily_NEEgf=[]\n",
    "daily_GPP=[]\n",
    "daily_R=[]\n",
    "for i in range(len(TP39_2018_dates)):\n",
    "    if TP39_2018_dates[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE.append(TP39_2018_NEE2[i])\n",
    "            daily_NEEgf.append(TP39_2018_NEE[i])\n",
    "            daily_GPP.append(TP39_2018_GPP[i])\n",
    "            daily_R.append(TP39_2018_R[i])\n",
    "            if i==len(TP39_2018_dates)-1:\n",
    "                TP39_daily_NEE[date]=np.mean(daily_NEE)\n",
    "                TP39_daily_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                TP39_daily_GPP[date]=np.mean(daily_GPP)\n",
    "                TP39_daily_R[date]=np.mean(daily_R)\n",
    "                \n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE.append(TP39_2018_NEE2[i])\n",
    "            daily_NEEgf.append(TP39_2018_NEE[i])\n",
    "            daily_GPP.append(TP39_2018_GPP[i])\n",
    "            daily_R.append(TP39_2018_R[i])\n",
    "            if np.floor(np.round(TP39_2018_dates[i],4))<np.floor(np.round(TP39_2018_dates[i+1],4)):\n",
    "                TP39_daily_NEE[date]=np.mean(daily_NEE)\n",
    "                TP39_daily_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                TP39_daily_GPP[date]=np.mean(daily_GPP)\n",
    "                TP39_daily_R[date]=np.mean(daily_R)\n",
    "\n",
    "                date+=1\n",
    "                daily_NEE=[]\n",
    "                daily_NEEgf=[]\n",
    "                daily_GPP=[]\n",
    "                daily_R=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert half-hourly to hourly data\n",
    "TP39_GPP=np.zeros(np.shape(C_GPP_TP39_array))*np.nan\n",
    "TP39_NEEgf=np.zeros(np.shape(C_GPP_TP39_array))*np.nan\n",
    "TP39_NEE=np.zeros(np.shape(C_GPP_TP39_array))*np.nan\n",
    "TP39_R=np.zeros(np.shape(C_GPP_TP39_array))*np.nan\n",
    "for i in range(len(date_array)-5):\n",
    "    TP39_GPP[i+5]=np.nanmean([TP39_2018_GPP[i*2],TP39_2018_GPP[i*2+1]])\n",
    "    TP39_NEEgf[i+5]=np.nanmean([TP39_2018_NEE[i*2],TP39_2018_NEE[i*2+1]])\n",
    "    TP39_NEE[i+5]=np.nanmean([TP39_2018_NEE2[i*2],TP39_2018_NEE2[i*2+1]])\n",
    "    TP39_R[i+5]=np.nanmean([TP39_2018_R[i*2],TP39_2018_R[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the daily average of the original SMUrF 2018 fluxes over TP39\n",
    "\n",
    "C_daily_NEE_TP39=np.zeros(365)*np.nan\n",
    "C_daily_GPP_TP39=np.zeros(365)*np.nan\n",
    "C_daily_R_TP39=np.zeros(365)*np.nan\n",
    "\n",
    "date=0\n",
    "daily_NEE_TP39_S=[]\n",
    "daily_GPP_TP39_S=[]\n",
    "daily_R_TP39_S=[]\n",
    "for i in range(len(date_array)):\n",
    "    if np.round(date_array[i],4)>=1:\n",
    "        if np.round(date_array[i],4)+1>=365:\n",
    "            daily_NEE_TP39_S.append(C_NEE_TP39_array[i])\n",
    "            daily_GPP_TP39_S.append(C_GPP_TP39_array[i])\n",
    "            daily_R_TP39_S.append(C_Reco_TP39_array[i])\n",
    "            if i==len(date_array)-1:\n",
    "                C_daily_NEE_TP39[date]=np.mean(daily_NEE_TP39_S)\n",
    "                C_daily_GPP_TP39[date]=np.mean(daily_GPP_TP39_S)\n",
    "                C_daily_R_TP39[date]=np.mean(daily_R_TP39_S)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_TP39_S.append(C_NEE_TP39_array[i])\n",
    "            daily_GPP_TP39_S.append(C_GPP_TP39_array[i])\n",
    "            daily_R_TP39_S.append(C_Reco_TP39_array[i])\n",
    "            if np.floor(np.round(date_array[i],4))<np.floor(np.round(date_array[i+1],4)):\n",
    "                C_daily_NEE_TP39[date]=np.mean(daily_NEE_TP39_S)\n",
    "                C_daily_GPP_TP39[date]=np.mean(daily_GPP_TP39_S)\n",
    "                C_daily_R_TP39[date]=np.mean(daily_R_TP39_S)\n",
    "                date+=1\n",
    "                daily_NEE_TP39_S=[]\n",
    "                daily_GPP_TP39_S=[]\n",
    "                daily_R_TP39_S=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in TP39 2019 flux tower data\n",
    "\n",
    "#*** CHANGE PATH & FILENAME ***\n",
    "TP39_2019_data=pd.read_csv('C:/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TP39_HH_2019.csv', usecols=[0,1,2,77,78,79]) #header=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP39_2019_dates=np.zeros([17520])*np.nan\n",
    "TP39_2019_NEE=np.zeros([17520])*np.nan\n",
    "TP39_2019_NEE2=np.zeros([17520])*np.nan\n",
    "TP39_2019_GPP=np.zeros([17520])*np.nan\n",
    "TP39_2019_R=np.zeros([17520])*np.nan\n",
    "\n",
    "for i in range(17520):\n",
    "    if 201901010000<=TP39_2019_data.iat[i,0]<202001010000:\n",
    "        TP39_2019_dates[i]=datetime.strptime(str(int(TP39_2019_data.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TP39_2019_data.iat[i,0])[8:10])+float(str(TP39_2019_data.iat[i,0])[10:12])/60)/24\n",
    "        #check that the value is greater than -9999 (value for empty measurements)\n",
    "        if TP39_2019_data.iat[i,2]>-9999:\n",
    "            TP39_2019_NEE2[i]=TP39_2019_data.iat[i,2] # save the NEE (non-filled)\n",
    "        if TP39_2019_data.iat[i,5]>-9999:\n",
    "            TP39_2019_NEE[i]=TP39_2019_data.iat[i,5] # save the gap-filled NEE \n",
    "        if TP39_2019_data.iat[i,3]>-9999:\n",
    "            TP39_2019_GPP[i]=TP39_2019_data.iat[i,3] # save the GPP\n",
    "        if TP39_2019_data.iat[i,4]>-9999:\n",
    "            TP39_2019_R[i]=TP39_2019_data.iat[i,4] # save the Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Original SMUrF 2019 fluxes over TP39\n",
    "C_GPP_TP39_2019_array=np.zeros(8765)*np.nan\n",
    "C_NEE_TP39_2019_array=np.zeros(8765)*np.nan\n",
    "C_Reco_TP39_2019_array=np.zeros(8765)*np.nan\n",
    "C_time_2019_array=np.zeros(8765)*np.nan\n",
    "for i in range(len(C_GPP_2019[:,0,0])):\n",
    "    C_time_2019_array[i]=C_time[i]\n",
    "    C_GPP_TP39_2019_array[i]=C_GPP_2019[i,4,6]\n",
    "    C_NEE_TP39_2019_array[i]=C_NEE_2019[i,4,6]\n",
    "    C_Reco_TP39_2019_array[i]=C_Reco_2019[i,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out erroneous NEE values between doy 195 and 198\n",
    "\n",
    "plt.rc('font',size=10)\n",
    "## ***Optional: uncomment to visualize erroneous values\n",
    "#with np.errstate(invalid='ignore'):\n",
    "#    plt.figure()\n",
    "#    plt.xlim(193,200)\n",
    "#    plt.scatter(TP39_2019_dates,TP39_2019_NEE2,label='TP39 NEE')\n",
    "#    plt.scatter(TP39_2019_dates[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],TP39_2019_NEE2[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],label='Erroneous TP39 NEE')\n",
    "#    plt.scatter(C_time_2019_array,C_NEE_TP39_2019_array,marker='*',label='SMUrF NEE')\n",
    "#    plt.legend()\n",
    "#    plt.xlabel('Day of year, 2019')\n",
    "#    plt.ylabel('NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#    plt.title('Erroneous TP39 flux tower NEE values')\n",
    "#    plt.show()\n",
    "    \n",
    "#    plt.figure()\n",
    "#    plt.xlim(193,200)\n",
    "#    plt.scatter(TP39_2019_dates,TP39_2019_NEE,label='TP39 NEEgf')\n",
    "#    plt.scatter(TP39_2019_dates[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],TP39_2019_NEE[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],label='Erroneous TP39 NEEgf')\n",
    "#    plt.scatter(C_time_2019_array,C_NEE_TP39_2019_array,marker='*',label='SMUrF NEE')\n",
    "#    plt.legend()\n",
    "#    plt.xlabel('Day of year, 2019')\n",
    "#    plt.ylabel('NEEgf ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#    plt.title('Erroneous TP39 flux tower NEEgf values')\n",
    "#    plt.show()\n",
    "    \n",
    "#    plt.figure()\n",
    "#    plt.xlim(193,200)\n",
    "#    plt.scatter(TP39_2019_dates,TP39_2019_GPP,label='TP39 GPP')\n",
    "#    plt.scatter(TP39_2019_dates[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],TP39_2019_GPP[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],label='Erroneous TP39 GPP')\n",
    "#    plt.scatter(C_time_2019_array,C_GPP_TP39_2019_array,marker='*',label='SMUrF GPP')\n",
    "#    plt.legend()\n",
    "#    plt.xlabel('Day of year, 2019')\n",
    "#    plt.ylabel('GPP ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#    plt.title('Erroneous TP39 flux tower GPP values')\n",
    "#    plt.show()\n",
    "    \n",
    "#    plt.figure()\n",
    "#    plt.xlim(193,200)\n",
    "#    plt.scatter(TP39_2019_dates,TP39_2019_R,label='TP39 Reco')\n",
    "#    plt.scatter(TP39_2019_dates[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],TP39_2019_R[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)],label='Erroneous TP39 Reco')\n",
    "#    plt.scatter(C_time_2019_array,C_Reco_TP39_2019_array,marker='*',label='SMUrF Reco')\n",
    "#    plt.legend()\n",
    "#    plt.xlabel('Day of year, 2019')\n",
    "#    plt.ylabel('Reco ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#    plt.title('Erroneous TP39 flux tower Reco values')\n",
    "#    plt.show()\n",
    "# ***\n",
    "\n",
    "with np.errstate(invalid='ignore'):\n",
    "    TP39_2019_NEE2[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)]= np.nan\n",
    "    TP39_2019_NEE[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)]= np.nan\n",
    "    TP39_2019_GPP[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)]= np.nan\n",
    "    TP39_2019_R[(TP39_2019_dates>195.04-5/24) & (TP39_2019_dates<198.6-5/24)]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP39_2019_hrly_GPP=np.zeros(np.shape(C_GPP_TP39_2019_array))*np.nan\n",
    "TP39_2019_hrly_NEEgf=np.zeros(np.shape(C_GPP_TP39_2019_array))*np.nan\n",
    "TP39_2019_hrly_NEE=np.zeros(np.shape(C_GPP_TP39_2019_array))*np.nan\n",
    "TP39_2019_hrly_R=np.zeros(np.shape(C_GPP_TP39_2019_array))*np.nan\n",
    "for i in range(len(date_array)-5):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        TP39_2019_hrly_GPP[i+5]=np.nanmean([TP39_2019_GPP[i*2],TP39_2019_GPP[i*2+1]])\n",
    "        TP39_2019_hrly_NEEgf[i+5]=np.nanmean([TP39_2019_NEE[i*2],TP39_2019_NEE[i*2+1]])\n",
    "        TP39_2019_hrly_NEE[i+5]=np.nanmean([TP39_2019_NEE2[i*2],TP39_2019_NEE2[i*2+1]])\n",
    "        TP39_2019_hrly_R[i+5]=np.nanmean([TP39_2019_R[i*2],TP39_2019_R[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take daily average of TP39 2019 flux tower data\n",
    "days_of_year=np.arange(1,366)+0.5\n",
    "TP39_daily_2019_NEE=np.zeros(365)*np.nan\n",
    "TP39_daily_2019_NEEgf=np.zeros(365)*np.nan\n",
    "TP39_daily_2019_GPP=np.zeros(365)*np.nan\n",
    "TP39_daily_2019_R=np.zeros(365)*np.nan\n",
    "\n",
    "date=0\n",
    "daily_NEE=[]\n",
    "daily_NEEgf=[]\n",
    "daily_GPP=[]\n",
    "daily_R=[]\n",
    "for i in range(len(TP39_2019_dates)):\n",
    "    if TP39_2019_dates[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE.append(TP39_2019_NEE2[i])\n",
    "            daily_NEEgf.append(TP39_2019_NEE[i])\n",
    "            daily_GPP.append(TP39_2019_GPP[i])\n",
    "            daily_R.append(TP39_2019_R[i])\n",
    "            if i==len(TP39_2019_dates)-1:\n",
    "                TP39_daily_2019_NEE[date]=np.mean(daily_NEE)\n",
    "                TP39_daily_2019_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                TP39_daily_2019_GPP[date]=np.mean(daily_GPP)\n",
    "                TP39_daily_2019_R[date]=np.mean(daily_R)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE.append(TP39_2019_NEE2[i])\n",
    "            daily_NEEgf.append(TP39_2019_NEE[i])\n",
    "            daily_GPP.append(TP39_2019_GPP[i])\n",
    "            daily_R.append(TP39_2019_R[i])\n",
    "            if np.floor(np.round(TP39_2019_dates[i],4))<np.floor(np.round(TP39_2019_dates[i+1],4)):\n",
    "                TP39_daily_2019_NEE[date]=np.mean(daily_NEE)\n",
    "                TP39_daily_2019_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                TP39_daily_2019_GPP[date]=np.mean(daily_GPP)\n",
    "                TP39_daily_2019_R[date]=np.mean(daily_R)\n",
    "                date+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_daily_2019_NEE_TP39=np.zeros(365)*np.nan\n",
    "C_daily_2019_GPP_TP39=np.zeros(365)*np.nan\n",
    "C_daily_2019_R_TP39=np.zeros(365)*np.nan\n",
    "\n",
    "#Take daily average of original SMUrF 2019 fluxes over TP39\n",
    "date=0\n",
    "daily_2019_NEE_TP39_C=[]\n",
    "daily_2019_GPP_TP39_C=[]\n",
    "daily_2019_R_TP39_C=[]\n",
    "for i in range(len(date_array)):\n",
    "    if np.round(date_array[i],4)>=1:\n",
    "        if np.round(date_array[i],4)+1>=365:\n",
    "            daily_2019_NEE_TP39_C.append(C_NEE_TP39_2019_array[i])\n",
    "            daily_2019_GPP_TP39_C.append(C_GPP_TP39_2019_array[i])\n",
    "            daily_2019_R_TP39_C.append(C_Reco_TP39_2019_array[i])\n",
    "            if i==len(date_array)-1:\n",
    "                C_daily_2019_NEE_TP39[date]=np.mean(daily_2019_NEE_TP39_C)\n",
    "                C_daily_2019_GPP_TP39[date]=np.mean(daily_2019_GPP_TP39_C)\n",
    "                C_daily_2019_R_TP39[date]=np.mean(daily_2019_R_TP39_C)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_2019_NEE_TP39_C.append(C_NEE_TP39_2019_array[i])\n",
    "            daily_2019_GPP_TP39_C.append(C_GPP_TP39_2019_array[i])\n",
    "            daily_2019_R_TP39_C.append(C_Reco_TP39_2019_array[i])\n",
    "            if np.floor(np.round(date_array[i],4))<np.floor(np.round(date_array[i+1],4)):\n",
    "                C_daily_2019_NEE_TP39[date]=np.mean(daily_2019_NEE_TP39_C)\n",
    "                C_daily_2019_GPP_TP39[date]=np.mean(daily_2019_GPP_TP39_C)\n",
    "                C_daily_2019_R_TP39[date]=np.mean(daily_2019_R_TP39_C)\n",
    "                date+=1\n",
    "                daily_2019_NEE_TP39_C=[]\n",
    "                daily_2019_GPP_TP39_C=[]\n",
    "                daily_2019_R_TP39_C=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at TPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in TPD flux tower data\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "TPD_2018_data=pd.read_csv('C:/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TPD_HH_2018.csv', usecols=[0,1,2,74,75,76]) #header=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPD_2018_dates=np.zeros([17520])*np.nan\n",
    "TPD_2018_NEE=np.zeros([17520])*np.nan\n",
    "TPD_2018_NEE2=np.zeros([17520])*np.nan\n",
    "TPD_2018_GPP=np.zeros([17520])*np.nan\n",
    "TPD_2018_R=np.zeros([17520])*np.nan\n",
    "for i in range(17520):\n",
    "    if 201801010000<=TPD_2018_data.iat[i,0]<202001010000:\n",
    "        TPD_2018_dates[i]=datetime.strptime(str(int(TPD_2018_data.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TPD_2018_data.iat[i,0])[8:10])+float(str(TPD_2018_data.iat[i,0])[10:12])/60)/24 #save the current date (and time)\n",
    "        #check that the value is greater than -9999 (value for empty measurements)\n",
    "        if TPD_2018_data.iat[i,2]>-9999:\n",
    "            TPD_2018_NEE2[i]=TPD_2018_data.iat[i,2] # save the NEE value\n",
    "        if TPD_2018_data.iat[i,5]>-9999:\n",
    "            TPD_2018_NEE[i]=TPD_2018_data.iat[i,5] # save the NEE value\n",
    "        if TPD_2018_data.iat[i,3]>-9999:\n",
    "            TPD_2018_GPP[i]=TPD_2018_data.iat[i,3] # save the NEE value\n",
    "        if TPD_2018_data.iat[i,4]>-9999:\n",
    "            TPD_2018_R[i]=TPD_2018_data.iat[i,4] # save the NEE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select original SMUrF data over TPD\n",
    "\n",
    "C_GPP_TPD_array=np.zeros(8765)*np.nan\n",
    "C_NEE_TPD_array=np.zeros(8765)*np.nan\n",
    "C_Reco_TPD_array=np.zeros(8765)*np.nan\n",
    "\n",
    "for i in range(len(C_GPP[:,0,0])):\n",
    "    C_GPP_TPD_array[i]=np.nanmean([C_GPP[i,2,2]])\n",
    "    C_NEE_TPD_array[i]=np.nanmean([C_NEE[i,2,2]])\n",
    "    C_Reco_TPD_array[i]=np.nanmean([C_Reco[i,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take daily average of TPD flux tower data\n",
    "\n",
    "days_of_year=np.arange(1,366)+0.5\n",
    "TPD_daily_NEE=np.zeros(365)*np.nan\n",
    "TPD_daily_NEEgf=np.zeros(365)*np.nan\n",
    "TPD_daily_GPP=np.zeros(365)*np.nan\n",
    "TPD_daily_R=np.zeros(365)*np.nan\n",
    "date=0\n",
    "daily_NEE=[]\n",
    "daily_NEEgf=[]\n",
    "daily_GPP=[]\n",
    "daily_R=[]\n",
    "for i in range(len(TPD_2018_dates)):\n",
    "    if TPD_2018_dates[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE.append(TPD_2018_NEE2[i])\n",
    "            daily_NEEgf.append(TPD_2018_NEE[i])\n",
    "            daily_GPP.append(TPD_2018_GPP[i])\n",
    "            daily_R.append(TPD_2018_R[i])\n",
    "            if i==len(TPD_2018_dates)-1:\n",
    "                TPD_daily_NEE[date]=np.mean(daily_NEE)\n",
    "                TPD_daily_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                TPD_daily_GPP[date]=np.mean(daily_GPP)\n",
    "                TPD_daily_R[date]=np.mean(daily_R)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE.append(TPD_2018_NEE2[i])\n",
    "            daily_NEEgf.append(TPD_2018_NEE[i])\n",
    "            daily_GPP.append(TPD_2018_GPP[i])\n",
    "            daily_R.append(TPD_2018_R[i])\n",
    "            if np.floor(np.round(TPD_2018_dates[i],4))<np.floor(np.round(TPD_2018_dates[i+1],4)):\n",
    "                TPD_daily_NEE[date]=np.mean(daily_NEE)\n",
    "                TPD_daily_NEEgf[date]=np.mean(daily_NEEgf)\n",
    "                TPD_daily_GPP[date]=np.mean(daily_GPP)\n",
    "                TPD_daily_R[date]=np.mean(daily_R)\n",
    "\n",
    "                date+=1\n",
    "                daily_NEE=[]\n",
    "                daily_NEEgf=[]\n",
    "                daily_GPP=[]\n",
    "                daily_R=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take hourly-average of TPD data\n",
    "\n",
    "TPD_GPP=np.zeros(np.shape(C_GPP_TPD_array))*np.nan\n",
    "TPD_NEE=np.zeros(np.shape(C_GPP_TPD_array))*np.nan\n",
    "TPD_NEEgf=np.zeros(np.shape(C_GPP_TPD_array))*np.nan\n",
    "TPD_R=np.zeros(np.shape(C_GPP_TPD_array))*np.nan\n",
    "for i in range(len(date_array)-5):\n",
    "    TPD_GPP[i+5]=np.nanmean([TPD_2018_GPP[i*2],TPD_2018_GPP[i*2+1]])\n",
    "    TPD_R[i+5]=np.nanmean([TPD_2018_R[i*2],TPD_2018_R[i*2+1]])\n",
    "    TPD_NEE[i+5]=np.nanmean([TPD_2018_NEE2[i*2],TPD_2018_NEE2[i*2+1]])\n",
    "    TPD_NEEgf[i+5]=np.nanmean([TPD_2018_NEE[i*2],TPD_2018_NEE[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take daily average of Original SMUrF 2018 data over TPD\n",
    "C_daily_NEE_TPD=np.zeros(365)*np.nan\n",
    "C_daily_GPP_TPD=np.zeros(365)*np.nan\n",
    "C_daily_R_TPD=np.zeros(365)*np.nan\n",
    "date=0\n",
    "daily_NEE_TPD_S=[]\n",
    "daily_GPP_TPD_S=[]\n",
    "daily_R_TPD_S=[]\n",
    "for i in range(len(date_array)):\n",
    "    if date_array[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_TPD_S.append(C_NEE_TPD_array[i])\n",
    "            daily_GPP_TPD_S.append(C_GPP_TPD_array[i])\n",
    "            daily_R_TPD_S.append(C_Reco_TPD_array[i])\n",
    "            if i==len(date_array)-1:\n",
    "                C_daily_NEE_TPD[date]=np.mean(daily_NEE_TPD_S)\n",
    "                C_daily_GPP_TPD[date]=np.mean(daily_GPP_TPD_S)\n",
    "                C_daily_R_TPD[date]=np.mean(daily_R_TPD_S)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_TPD_S.append(C_NEE_TPD_array[i])\n",
    "            daily_GPP_TPD_S.append(C_GPP_TPD_array[i])\n",
    "            daily_R_TPD_S.append(C_Reco_TPD_array[i])\n",
    "            if np.floor(np.round(date_array[i],4))<np.floor(np.round(date_array[i+1],4)):\n",
    "                C_daily_NEE_TPD[date]=np.mean(daily_NEE_TPD_S)\n",
    "                C_daily_GPP_TPD[date]=np.mean(daily_GPP_TPD_S)\n",
    "                C_daily_R_TPD[date]=np.mean(daily_R_TPD_S)\n",
    "                date+=1\n",
    "                daily_NEE_TPD_S=[]\n",
    "                daily_GPP_TPD_S=[]\n",
    "                daily_R_TPD_S=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import TPD 2019 flux tower data\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "TPD_2019_data=pd.read_csv('C:/Users/kitty/Documents/Research/SIF/Flux_Tower/Turkey_Point/TPD_HH_2019.csv', usecols=[0,1,2,74,75,76]) #header=1\n",
    "\n",
    "TPD_2019_dates=np.zeros([17520])*np.nan\n",
    "TPD_2019_NEE=np.zeros([17520])*np.nan\n",
    "TPD_2019_NEE2=np.zeros([17520])*np.nan\n",
    "TPD_2019_GPP=np.zeros([17520])*np.nan\n",
    "TPD_2019_R=np.zeros([17520])*np.nan\n",
    "n=0\n",
    "m=0\n",
    "date=1\n",
    "for i in range(17520):\n",
    "    if 201901010000<=TPD_2019_data.iat[i,0]<202001010000:\n",
    "        TPD_2019_dates[i]=datetime.strptime(str(int(TPD_2019_data.iat[i,0])),'%Y%m%d%H%M').timetuple().tm_yday+(float(str(TPD_2019_data.iat[i,0])[8:10])+float(str(TPD_2019_data.iat[i,0])[10:12])/60)/24 #save the current date (and time)\n",
    "        #check that the value is greater than -9999 (value for empty measurements)\n",
    "        if TPD_2019_data.iat[i,2]>-9999:\n",
    "            TPD_2019_NEE2[i]=TPD_2019_data.iat[i,2] # save the NEE (non-gapfilled)\n",
    "        if TPD_2019_data.iat[i,5]>-9999:\n",
    "            TPD_2019_NEE[i]=TPD_2019_data.iat[i,5] # save the gap-filled NEE\n",
    "        if TPD_2019_data.iat[i,3]>-9999:\n",
    "            TPD_2019_GPP[i]=TPD_2019_data.iat[i,3] # save the GPP\n",
    "        if TPD_2019_data.iat[i,4]>-9999:\n",
    "            TPD_2019_R[i]=TPD_2019_data.iat[i,4] # save the Reco\n",
    "\n",
    "days_of_year=np.arange(1,366)+0.5\n",
    "TPD_daily_2019_NEE=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_NEEgf=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_GPP=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_R=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_NEE_std=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_NEEgf_std=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_GPP_std=np.zeros(365)*np.nan\n",
    "TPD_daily_2019_R_std=np.zeros(365)*np.nan\n",
    "date=0\n",
    "daily_2019_NEE=[]\n",
    "daily_2019_NEEgf=[]\n",
    "daily_2019_GPP=[]\n",
    "daily_2019_R=[]\n",
    "for i in range(len(TPD_2019_dates)):\n",
    "    if TPD_2019_dates[i]>=1:\n",
    "        if date+1>=365:\n",
    "            daily_2019_NEE.append(TPD_2019_NEE2[i])\n",
    "            daily_2019_NEEgf.append(TPD_2019_NEE[i])\n",
    "            daily_2019_GPP.append(TPD_2019_GPP[i])\n",
    "            daily_2019_R.append(TPD_2019_R[i])\n",
    "            if i==len(TPD_2019_dates)-1:\n",
    "                TPD_daily_2019_NEE[date]=np.mean(daily_2019_NEE)\n",
    "                TPD_daily_2019_NEEgf[date]=np.mean(daily_2019_NEEgf)\n",
    "                TPD_daily_2019_GPP[date]=np.mean(daily_2019_GPP)\n",
    "                TPD_daily_2019_R[date]=np.mean(daily_2019_R)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_2019_NEE.append(TPD_2019_NEE2[i])\n",
    "            daily_2019_NEEgf.append(TPD_2019_NEE[i])\n",
    "            daily_2019_GPP.append(TPD_2019_GPP[i])\n",
    "            daily_2019_R.append(TPD_2019_R[i])\n",
    "            if np.floor(np.round(TPD_2019_dates[i],4))<np.floor(np.round(TPD_2019_dates[i+1],4)):\n",
    "                TPD_daily_2019_NEE[date]=np.mean(daily_2019_NEE)\n",
    "                TPD_daily_2019_NEEgf[date]=np.mean(daily_2019_NEEgf)\n",
    "                TPD_daily_2019_GPP[date]=np.mean(daily_2019_GPP)\n",
    "                TPD_daily_2019_R[date]=np.mean(daily_2019_R)\n",
    "                date+=1\n",
    "                daily_2019_NEE=[]\n",
    "                daily_2019_NEEgf=[]\n",
    "                daily_2019_GPP=[]\n",
    "                daily_2019_R=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Original SMUrF 2019 fluxes over TPD\n",
    "C_GPP_TPD_2019_array=np.zeros(8765)*np.nan\n",
    "C_NEE_TPD_2019_array=np.zeros(8765)*np.nan\n",
    "C_Reco_TPD_2019_array=np.zeros(8765)*np.nan\n",
    "\n",
    "for i in range(len(C_GPP_2019[:,0,0])):\n",
    "    C_GPP_TPD_2019_array[i]=np.nanmean([C_GPP_2019[i,2,2]])\n",
    "    C_NEE_TPD_2019_array[i]=np.nanmean([C_NEE_2019[i,2,2]])\n",
    "    C_Reco_TPD_2019_array[i]=np.nanmean([C_Reco_2019[i,2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average TPD 2019 flux tower data to hourly resolution\n",
    "\n",
    "TPD_2019_hrly_GPP=np.zeros(np.shape(C_GPP_TPD_2019_array))*np.nan\n",
    "TPD_2019_hrly_NEE=np.zeros(np.shape(C_GPP_TPD_2019_array))*np.nan\n",
    "TPD_2019_hrly_NEEgf=np.zeros(np.shape(C_GPP_TPD_2019_array))*np.nan\n",
    "TPD_2019_hrly_R=np.zeros(np.shape(C_GPP_TPD_2019_array))*np.nan\n",
    "for i in range(len(date_array)-5):\n",
    "    TPD_2019_hrly_GPP[i+5]=np.nanmean([TPD_2019_GPP[i*2],TPD_2019_GPP[i*2+1]])\n",
    "    TPD_2019_hrly_NEE[i+5]=np.nanmean([TPD_2019_NEE2[i*2],TPD_2019_NEE2[i*2+1]])\n",
    "    TPD_2019_hrly_NEEgf[i+5]=np.nanmean([TPD_2019_NEE[i*2],TPD_2019_NEE[i*2+1]])\n",
    "    TPD_2019_hrly_R[i+5]=np.nanmean([TPD_2019_R[i*2],TPD_2019_R[i*2+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** If you have not saved the Updated SMUrF data over the flux towers (see \n",
    "#'TROPOMI_SMUrF_CSIF_SMUrF_Fluxtower_Seasonal_Comparison-V061_clean.py') run this block of code:\n",
    "\n",
    "#Load in SMUrF data and crop to flux tower locations for 2018:\n",
    "S_time=[]\n",
    "S_lats=[]\n",
    "S_lons=[]\n",
    "\n",
    "S_Reco_Borden=[]\n",
    "S_NEE_Borden=[]\n",
    "S_GPP_Borden=[]\n",
    "\n",
    "S_Reco_TP39=[]\n",
    "S_NEE_TP39=[]\n",
    "S_GPP_TP39=[]\n",
    "\n",
    "S_Reco_TPD=[]\n",
    "S_NEE_TPD=[]\n",
    "S_GPP_TPD=[]\n",
    "\n",
    "# *** CHANGE PATH ***\n",
    "S_path = 'C:/Users/kitty/Documents/Research/SIF/SMUrF/output2018_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_V3_temp_impervious_R_shore_corr_V061_8day/easternCONUS/hourly_flux_GMIS_Toronto_fixed_border_ISA_a_w_sd_era5/'\n",
    "# *** CHANGE FILENAME ***\n",
    "S_fn = 'hrly_mean_GPP_Reco_NEE_easternCONUS_2018' # filename (without the month)\n",
    "\n",
    "for j in range(1,13):\n",
    "    try:\n",
    "        #load in the data\n",
    "        if j<10:\n",
    "            f=Dataset(S_path+S_fn+'0'+str(j)+'.nc')\n",
    "        else:\n",
    "            f=Dataset(S_path+S_fn+str(j)+'.nc')\n",
    "        \n",
    "        S_Reco=f.variables['Reco_mean'][:]\n",
    "        S_GPP=f.variables['GPP_mean'][:]\n",
    "        S_NEE=f.variables['NEE_mean'][:]\n",
    "        \n",
    "        if len(S_time)==0:\n",
    "            # If it is the first file start an array for each variable and save lat/lon & fluxes\n",
    "            S_lats=f.variables['lat'][:]\n",
    "            S_lons=f.variables['lon'][:]\n",
    "            S_time=f.variables['time'][:]/24/3600-start_of_year-5/24 #convert seconds since 1970 to days and subtract start of year and adjust to local time\n",
    "              \n",
    "            # *** NOTE: if you changed the extent from the default settings when running SMUrF you will need to \n",
    "            # change the indices below to find the correct pixels over the flux towers ***\n",
    "            S_GPP_Borden = np.nanmean([S_GPP[:,458,230],S_GPP[:,458,231],S_GPP[:,458,232],S_GPP[:,459,230],S_GPP[:,459,231],S_GPP[:,459,232],S_GPP[:,460,232]],axis=0)\n",
    "            S_Reco_Borden = np.nanmean([S_Reco[:,458,230],S_Reco[:,458,231],S_Reco[:,458,232],S_Reco[:,459,230],S_Reco[:,459,231],S_Reco[:,459,232],S_Reco[:,460,232]],axis=0)\n",
    "            S_NEE_Borden = np.nanmean([S_NEE[:,458,230],S_NEE[:,458,231],S_NEE[:,458,232],S_NEE[:,459,230],S_NEE[:,459,231],S_NEE[:,459,232],S_NEE[:,460,232]],axis=0)\n",
    "            \n",
    "            S_GPP_TP39 = np.nanmean(S_GPP[:,73:75,129:131],axis=(1,2))\n",
    "            S_Reco_TP39 = np.nanmean(S_Reco[:,73:75,129:131],axis=(1,2))\n",
    "            S_NEE_TP39 = np.nanmean(S_NEE[:,73:75,129:131],axis=(1,2))\n",
    "            \n",
    "            S_GPP_TPD = np.nanmean(S_GPP[:,55:58,80:83],axis=(1,2))\n",
    "            S_Reco_TPD = np.nanmean(S_Reco[:,55:58,80:83],axis=(1,2))\n",
    "            S_NEE_TPD = np.nanmean(S_NEE[:,55:58,80:83],axis=(1,2))\n",
    "            \n",
    "        else:\n",
    "            #Otherwise append fluxes to the array\n",
    "            S_GPP_Borden = np.concatenate((S_GPP_Borden,np.nanmean([S_GPP[:,458,230],S_GPP[:,458,231],S_GPP[:,458,232],S_GPP[:,459,230],S_GPP[:,459,231],S_GPP[:,459,232],S_GPP[:,460,232]],axis=0)),axis=0)\n",
    "            S_Reco_Borden = np.concatenate((S_Reco_Borden,np.nanmean([S_Reco[:,458,230],S_Reco[:,458,231],S_Reco[:,458,232],S_Reco[:,459,230],S_Reco[:,459,231],S_Reco[:,459,232],S_Reco[:,460,232]],axis=0)),axis=0)\n",
    "            S_NEE_Borden = np.concatenate((S_NEE_Borden,np.nanmean([S_NEE[:,458,230],S_NEE[:,458,231],S_NEE[:,458,232],S_NEE[:,459,230],S_NEE[:,459,231],S_NEE[:,459,232],S_NEE[:,460,232]],axis=0)),axis=0)\n",
    "            \n",
    "            S_GPP_TP39 = np.concatenate((S_GPP_TP39,np.nanmean(S_GPP[:,73:75,129:131],axis=(1,2))),axis=0)\n",
    "            S_Reco_TP39 = np.concatenate((S_Reco_TP39,np.nanmean(S_Reco[:,73:75,129:131],axis=(1,2))),axis=0)\n",
    "            S_NEE_TP39 = np.concatenate((S_NEE_TP39,np.nanmean(S_NEE[:,73:75,129:131],axis=(1,2))),axis=0)\n",
    "            \n",
    "            S_GPP_TPD = np.concatenate((S_GPP_TPD,np.nanmean(S_GPP[:,55:58,80:83],axis=(1,2))),axis=0)\n",
    "            S_Reco_TPD = np.concatenate((S_Reco_TPD,np.nanmean(S_Reco[:,55:58,80:83],axis=(1,2))),axis=0)\n",
    "            S_NEE_TPD = np.concatenate((S_NEE_TPD,np.nanmean(S_NEE[:,55:58,80:83],axis=(1,2))),axis=0)\n",
    "            \n",
    "            S_time=np.concatenate((S_time,(f.variables['time'][:]/24/3600-start_of_year-5/24)),axis=0)\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "del(S_GPP,S_Reco,S_NEE)\n",
    "\n",
    "S_GPP_Borden = np.concatenate((S_GPP_Borden,np.ones(5)*np.nan),axis=0)\n",
    "S_Reco_Borden = np.concatenate((S_Reco_Borden,np.ones(5)*np.nan),axis=0)\n",
    "S_NEE_Borden = np.concatenate((S_NEE_Borden,np.ones(5)*np.nan),axis=0)\n",
    "\n",
    "S_GPP_TP39 = np.concatenate((S_GPP_TP39,np.ones(5)*np.nan),axis=0)\n",
    "S_Reco_TP39 = np.concatenate((S_Reco_TP39,np.ones(5)*np.nan),axis=0)\n",
    "S_NEE_TP39 = np.concatenate((S_NEE_TP39,np.ones(5)*np.nan),axis=0)\n",
    "\n",
    "S_GPP_TPD = np.concatenate((S_GPP_TPD,np.ones(5)*np.nan),axis=0)\n",
    "S_Reco_TPD = np.concatenate((S_Reco_TPD,np.ones(5)*np.nan),axis=0)\n",
    "S_NEE_TPD = np.concatenate((S_NEE_TPD,np.ones(5)*np.nan),axis=0)\n",
    "\n",
    "S_time=np.concatenate((S_time,np.ones(5)*np.nan),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in SMUrF data and crop to flux tower locations for 2019:\n",
    "S_time=[]\n",
    "S_lats=[]\n",
    "S_lons=[]\n",
    "\n",
    "S_Reco_TP39_2019=[]\n",
    "S_NEE_TP39_2019=[]\n",
    "S_GPP_TP39_2019=[]\n",
    "\n",
    "S_Reco_TPD_2019=[]\n",
    "S_NEE_TPD_2019=[]\n",
    "S_GPP_TPD_2019=[]\n",
    "\n",
    "# *** CHANGE PATH ***\n",
    "S_path = 'C:/Users/kitty/Documents/Research/SIF/SMUrF/output2019_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_V3_temp_impervious_R_shore_corr_V061_8day/easternCONUS/hourly_flux_GMIS_Toronto_fixed_border_ISA_a_w_sd_era5/'\n",
    "# *** CHANGE FILENAME ***\n",
    "S_fn = 'hrly_mean_GPP_Reco_NEE_easternCONUS_2019' # filename (without the month)\n",
    "\n",
    "for j in range(1,13):\n",
    "    try:\n",
    "        #load in the data\n",
    "        if j<10:\n",
    "            f=Dataset(S_path+S_fn+'0'+str(j)+'.nc')\n",
    "        else:\n",
    "            f=Dataset(S_path+S_fn+str(j)+'.nc')\n",
    "        \n",
    "        S_Reco=f.variables['Reco_mean'][:]\n",
    "        S_GPP=f.variables['GPP_mean'][:]\n",
    "        S_NEE=f.variables['NEE_mean'][:]\n",
    "        \n",
    "        if len(S_time)==0:\n",
    "            # If it is the first file start an array for each variable and save lat/lon\n",
    "            S_lats=f.variables['lat'][:]\n",
    "            S_lons=f.variables['lon'][:]\n",
    "            S_time=f.variables['time'][:]/24/3600-start_of_year-5/24 #convert seconds since 1970 to days and subtract start of year and adjust to local time\n",
    "                 \n",
    "            # *** NOTE: if you changed the extent from the default settings when running SMUrF you will need to \n",
    "            # change the indices below to find the correct pixels over the flux towers ***\n",
    "            S_GPP_TP39_2019 = np.nanmean(S_GPP[:,73:75,129:131],axis=(1,2))\n",
    "            S_Reco_TP39_2019 = np.nanmean(S_Reco[:,73:75,129:131],axis=(1,2))\n",
    "            S_NEE_TP39_2019 = np.nanmean(S_NEE[:,73:75,129:131],axis=(1,2))\n",
    "            \n",
    "            S_GPP_TPD_2019 = np.nanmean(S_GPP[:,55:58,80:83],axis=(1,2))\n",
    "            S_Reco_TPD_2019 = np.nanmean(S_Reco[:,55:58,80:83],axis=(1,2))\n",
    "            S_NEE_TPD_2019 = np.nanmean(S_NEE[:,55:58,80:83],axis=(1,2))\n",
    "            \n",
    "        else:\n",
    "            #Otherwise append to the array\n",
    "            S_GPP_TP39_2019 = np.concatenate((S_GPP_TP39_2019,np.nanmean(S_GPP[:,73:75,129:131],axis=(1,2))),axis=0)\n",
    "            S_Reco_TP39_2019 = np.concatenate((S_Reco_TP39_2019,np.nanmean(S_Reco[:,73:75,129:131],axis=(1,2))),axis=0)\n",
    "            S_NEE_TP39_2019 = np.concatenate((S_NEE_TP39_2019,np.nanmean(S_NEE[:,73:75,129:131],axis=(1,2))),axis=0)\n",
    "            \n",
    "            S_GPP_TPD_2019 = np.concatenate((S_GPP_TPD_2019,np.nanmean(S_GPP[:,55:58,80:83],axis=(1,2))),axis=0)\n",
    "            S_Reco_TPD_2019 = np.concatenate((S_Reco_TPD_2019,np.nanmean(S_Reco[:,55:58,80:83],axis=(1,2))),axis=0)\n",
    "            S_NEE_TPD_2019 = np.concatenate((S_NEE_TPD_2019,np.nanmean(S_NEE[:,55:58,80:83],axis=(1,2))),axis=0)\n",
    "            \n",
    "            S_time=np.concatenate((S_time,(f.variables['time'][:]/24/3600-start_of_year-5/24)),axis=0)\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "del(S_GPP,S_Reco,S_NEE)\n",
    "\n",
    "S_GPP_2019_TP39 = np.concatenate((S_GPP_TP39_2019,np.ones(5)*np.nan),axis=0)\n",
    "S_Reco_2019_TP39 = np.concatenate((S_Reco_TP39_2019,np.ones(5)*np.nan),axis=0)\n",
    "S_NEE_2019_TP39 = np.concatenate((S_NEE_TP39_2019,np.ones(5)*np.nan),axis=0)\n",
    "\n",
    "S_GPP_2019_TPD = np.concatenate((S_GPP_TPD_2019,np.ones(5)*np.nan),axis=0)\n",
    "S_Reco_2019_TPD = np.concatenate((S_Reco_TPD_2019,np.ones(5)*np.nan),axis=0)\n",
    "S_NEE_2019_TPD = np.concatenate((S_NEE_TPD_2019,np.ones(5)*np.nan),axis=0)\n",
    "\n",
    "S_time=np.concatenate((S_time,np.ones(5)*np.nan),axis=0)\n",
    "\n",
    "#End of load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** IF you previously saved SMUrF fluxes over flux towers (see \n",
    "# 'TROPOMI_SMUrF_CSIF_SMUrF_Fluxtower_Seasonal_Comparison-V061_clean.py') uncomment the lines below to load it in (faster)\n",
    "# instead of running the load in block above ***\n",
    "\n",
    "## Load in Updated SMUrF fluxes over Borden Forest\n",
    "## *** CHANGE PATH & FILENAME ***\n",
    "#g = Dataset('E:/Research/SMUrF/output2018_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_temp_impervious_R_V061_8day/SMUrF_Borden_fluxes.nc')\n",
    "#S_test_NEE_Borden=g.variables['NEE'][:]\n",
    "#S_test_GPP_Borden=g.variables['GPP'][:]\n",
    "#S_test_Reco_Borden=g.variables['Reco'][:]\n",
    "#S_test_time=g.variables['time'][:]\n",
    "#g.close()\n",
    "\n",
    "## Load in Updated SMUrF fluxes over TP39\n",
    "## *** CHANGE PATH & FILENAME ***\n",
    "#g = Dataset('E:/Research/SMUrF/output2018_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_temp_impervious_R_V061_8day/SMUrF_TP39_fluxes.nc')\n",
    "#S_test_NEE_TP39=g.variables['NEE'][:]\n",
    "#S_test_GPP_TP39=g.variables['GPP'][:]\n",
    "#S_test_Reco_TP39=g.variables['Reco'][:]\n",
    "#S_test_time=g.variables['time'][:]\n",
    "#g.close()\n",
    "\n",
    "## Load in Updated SMUrF fluxes over TPD\n",
    "## *** CHANGE PATH & FILENAME ***\n",
    "#g = Dataset('E:/Research/SMUrF/output2018_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_temp_impervious_R_V061_8day/SMUrF_TPD_fluxes_2018.nc')\n",
    "#S_test_NEE_TPD=g.variables['NEE'][:]\n",
    "#S_test_GPP_TPD=g.variables['GPP'][:]\n",
    "#S_test_Reco_TPD=g.variables['Reco'][:]\n",
    "#S_test_time=g.variables['time'][:]\n",
    "#g.close()\n",
    "\n",
    "## Load in Updated SMUrF fluxes over TPD & TP39 for 2019\n",
    "## *** CHANGE PATH & FILENAME ***\n",
    "#g = Dataset('E:/Research/SMUrF/output2019_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_temp_impervious_R_V061_8day/SMUrF_TP39_fluxes.nc')\n",
    "#S_test_NEE_2019_TP39=g.variables['NEE'][:]\n",
    "#S_test_GPP_2019_TP39=g.variables['GPP'][:]\n",
    "#S_test_Reco_2019_TP39=g.variables['Reco'][:]\n",
    "#S_test_time=g.variables['time'][:]\n",
    "#g.close()\n",
    "\n",
    "#g = Dataset('E:/Research/SMUrF/output2019_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_temp_impervious_R_V061_8day/SMUrF_TPD_fluxes_2019.nc')\n",
    "#S_test_NEE_2019_TPD=g.variables['NEE'][:]\n",
    "#S_test_GPP_2019_TPD=g.variables['GPP'][:]\n",
    "#S_test_Reco_2019_TPD=g.variables['Reco'][:]\n",
    "#S_test_time=g.variables['time'][:]\n",
    "#g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the daily average Updated SMUrF over each of the fluxtowers\n",
    "\n",
    "S_daily_NEE=np.zeros(365)*np.nan\n",
    "S_daily_GPP=np.zeros(365)*np.nan\n",
    "S_daily_R=np.zeros(365)*np.nan\n",
    "daily_NEE_S=[]\n",
    "daily_GPP_S=[]\n",
    "daily_R_S=[]\n",
    "\n",
    "S_daily_NEE_TP39=np.zeros(365)*np.nan\n",
    "S_daily_GPP_TP39=np.zeros(365)*np.nan\n",
    "S_daily_R_TP39=np.zeros(365)*np.nan\n",
    "daily_NEE_TP39_S=[]\n",
    "daily_GPP_TP39_S=[]\n",
    "daily_R_TP39_S=[]\n",
    "\n",
    "S_daily_NEE_TPD=np.zeros(365)*np.nan\n",
    "S_daily_GPP_TPD=np.zeros(365)*np.nan\n",
    "S_daily_R_TPD=np.zeros(365)*np.nan\n",
    "daily_NEE_TPD_S=[]\n",
    "daily_GPP_TPD_S=[]\n",
    "daily_R_TPD_S=[]\n",
    "\n",
    "date=0\n",
    "for i in range(len(date_array)):\n",
    "    if np.round(date_array[i],4)>=1:\n",
    "        if date+1>=365:\n",
    "            daily_NEE_S.append(S_NEE_Borden[i])\n",
    "            daily_GPP_S.append(S_GPP_Borden[i])\n",
    "            daily_R_S.append(S_Reco_Borden[i])\n",
    "            \n",
    "            daily_NEE_TP39_S.append(S_NEE_TP39[i])\n",
    "            daily_GPP_TP39_S.append(S_GPP_TP39[i])\n",
    "            daily_R_TP39_S.append(S_Reco_TP39[i])\n",
    "            \n",
    "            daily_NEE_TPD_S.append(S_NEE_TPD[i])\n",
    "            daily_GPP_TPD_S.append(S_GPP_TPD[i])\n",
    "            daily_R_TPD_S.append(S_Reco_TPD[i])\n",
    "            if i==len(date_array)-1:\n",
    "                S_daily_NEE[date]=np.mean(daily_NEE_S)\n",
    "                S_daily_GPP[date]=np.mean(daily_GPP_S)\n",
    "                S_daily_R[date]=np.mean(daily_R_S)\n",
    "                \n",
    "                S_daily_NEE_TP39[date]=np.mean(daily_NEE_TP39_S)\n",
    "                S_daily_GPP_TP39[date]=np.mean(daily_GPP_TP39_S)\n",
    "                S_daily_R_TP39[date]=np.mean(daily_R_TP39_S)\n",
    "                \n",
    "                S_daily_NEE_TPD[date]=np.mean(daily_NEE_TPD_S)\n",
    "                S_daily_GPP_TPD[date]=np.mean(daily_GPP_TPD_S)\n",
    "                S_daily_R_TPD[date]=np.mean(daily_R_TPD_S)\n",
    "                date+=1\n",
    "        else:\n",
    "            daily_NEE_S.append(S_NEE_Borden[i])\n",
    "            daily_GPP_S.append(S_GPP_Borden[i])\n",
    "            daily_R_S.append(S_Reco_Borden[i])\n",
    "            \n",
    "            daily_NEE_TP39_S.append(S_NEE_TP39[i])\n",
    "            daily_GPP_TP39_S.append(S_GPP_TP39[i])\n",
    "            daily_R_TP39_S.append(S_Reco_TP39[i])\n",
    "            \n",
    "            daily_NEE_TPD_S.append(S_NEE_TPD[i])\n",
    "            daily_GPP_TPD_S.append(S_GPP_TPD[i])\n",
    "            daily_R_TPD_S.append(S_Reco_TPD[i])\n",
    "            if np.floor(np.round(date_array[i],4))<np.floor(np.round(date_array[i+1],4)):\n",
    "                S_daily_NEE[date]=np.mean(daily_NEE_S)\n",
    "                S_daily_GPP[date]=np.mean(daily_GPP_S)\n",
    "                S_daily_R[date]=np.mean(daily_R_S)\n",
    "                \n",
    "                S_daily_NEE_TP39[date]=np.mean(daily_NEE_TP39_S)\n",
    "                S_daily_GPP_TP39[date]=np.mean(daily_GPP_TP39_S)\n",
    "                S_daily_R_TP39[date]=np.mean(daily_R_TP39_S)\n",
    "                \n",
    "                S_daily_NEE_TPD[date]=np.mean(daily_NEE_TPD_S)\n",
    "                S_daily_GPP_TPD[date]=np.mean(daily_GPP_TPD_S)\n",
    "                S_daily_R_TPD[date]=np.mean(daily_R_TPD_S)\n",
    "            \n",
    "                date+=1\n",
    "                daily_NEE_S=[]\n",
    "                daily_GPP_S=[]\n",
    "                daily_R_S=[]\n",
    "                \n",
    "                daily_NEE_TP39_S=[]\n",
    "                daily_GPP_TP39_S=[]\n",
    "                daily_R_TP39_S=[]\n",
    "                \n",
    "                daily_NEE_TPD_S=[]\n",
    "                daily_GPP_TPD_S=[]\n",
    "                daily_R_TPD_S=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Optional: Uncomment to viusalize 2018-2019 hourly fluxes\n",
    "\n",
    "#plt.xlim(1,365*2)\n",
    "#plt.scatter(C_time_array,S_NEE_Borden,label='TROPOMI-SMUrF',s=8)\n",
    "#plt.scatter(C_time_array,C_NEE_array,label='CSIF-SMUrF',s=4)\n",
    "#plt.scatter(C_time_array,Borden_NEE,label='Fluxtower',c='k',s=2)\n",
    "#plt.legend()\n",
    "#plt.xlabel('Day of Year')\n",
    "#plt.ylabel('NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('Borden Modelled NEE')\n",
    "#plt.show()\n",
    "\n",
    "#plt.xlim(1,365*2)\n",
    "#plt.scatter(C_time_array,S_NEE_TP39,label='TROPOMI-SMUrF',s=8)\n",
    "#plt.scatter(C_time_array,C_NEE_TP39_array,label='CSIF-SMUrF',s=4)\n",
    "#plt.scatter(C_time_array,TP39_NEE,label='Fluxtower',c='k',s=2)\n",
    "#plt.scatter(C_time_array+365,S_NEE_2019_TP39,c='tab:blue',s=8)\n",
    "#plt.scatter(C_time_array+365,C_NEE_TP39_2019_array,c='tab:orange',s=4)\n",
    "#plt.scatter(C_time_array+365,TP39_2019_hrly_NEE,c='k',s=2)\n",
    "#plt.xlabel('Day of Year')\n",
    "#plt.ylabel('NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('TP39 Modelled NEE')\n",
    "#plt.show()\n",
    "\n",
    "#plt.xlim(1,365*2)\n",
    "#plt.scatter(C_time_array,S_NEE_TPD,label='TROPOMI-SMUrF',s=8)\n",
    "#plt.scatter(C_time_array,C_NEE_TPD_array,label='CSIF-SMUrF',s=4)\n",
    "#plt.scatter(C_time_array,TPD_NEE,label='Fluxtower',c='k',s=2)\n",
    "#plt.scatter(C_time_array+365,S_NEE_2019_TPD,c='tab:blue',s=8)\n",
    "#plt.scatter(C_time_array+365,C_NEE_TPD_2019_array,c='tab:orange',s=4)\n",
    "#plt.scatter(C_time_array+365,TPD_2019_hrly_NEE,c='k',s=2)\n",
    "#plt.xlabel('Day of Year')\n",
    "#plt.ylabel('NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('TPD Modelled NEE')\n",
    "#plt.show()\n",
    "\n",
    "# End of uncomment ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font',size=22)\n",
    "\n",
    "fig, ax = plt.subplots(3,3,sharex=True,figsize=(11,8))\n",
    "ax[0,0].set_xlim(1,365)\n",
    "ax[0,0].set_ylim(-2,22)\n",
    "ax[0,1].set_ylim(-2,22)\n",
    "ax[0,2].set_ylim(-2,22)\n",
    "\n",
    "l0,=ax[0,0].plot(days_of_year,Borden_daily_GPPgf+50,label='Borden Fluxtower',c='k')\n",
    "ax[0,0].plot(days_of_year,Borden_daily_GPPgf,label='Borden 2018',c='k')\n",
    "\n",
    "ls0,=ax[0,0].plot(days_of_year,days_of_year+50,label='Original SMUrF',c='#006BA4')\n",
    "ax[0,0].plot(days_of_year,C_daily_GPP,label='Original SMUrF',c='#006BA4',alpha=0.75)\n",
    "\n",
    "ls1,=ax[0,0].plot(days_of_year,days_of_year+50,label='Updated SMUrF',c='#FF800E',linestyle='--')\n",
    "ax[0,0].plot(days_of_year,S_daily_GPP,label='Updated SMUrF',c='#FF800E', alpha=0.75,linestyle='--')\n",
    "ax[0,0].set_title('GPP')\n",
    "\n",
    "l1=ax[0,1].scatter(days_of_year,TP39_daily_GPP+50,label='TP39 Fluxtower',c='k')\n",
    "ax[0,1].plot(days_of_year,TP39_daily_GPP,label='TP39 2018-2019',c='k')\n",
    "ax[0,1].plot(days_of_year,C_daily_GPP_TP39,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[0,1].plot(days_of_year,S_daily_GPP_TP39,label='Updated SMUrF',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "ax[0,0].set_ylabel('GPP')\n",
    "\n",
    "l2=ax[0,2].scatter(days_of_year,TPD_daily_GPP+50,label='TPD Fluxtower',c='k')\n",
    "ax[0,2].plot(days_of_year,TPD_daily_GPP,label='TPD 2018-2019',c='k')\n",
    "ax[0,2].plot(days_of_year,C_daily_GPP_TPD,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[0,2].plot(days_of_year,S_daily_GPP_TPD,label='Updated SMUrF',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[1,0].set_ylim(-1,22)\n",
    "ax[1,1].set_ylim(-1,22)\n",
    "ax[1,2].set_ylim(-1,22)\n",
    "\n",
    "ax[1,0].plot(days_of_year,Borden_daily_Rgf,label='Borden 2018-2020',c='k')\n",
    "ax[1,0].plot(days_of_year,C_daily_R,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[1,0].plot(days_of_year,S_daily_R,label='Updated SMUrF',c='#FF800E', alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[0,0].set_title('GPP')\n",
    "\n",
    "ax[1,1].plot(days_of_year,TP39_daily_R,label='TP39 2018-2019',c='k')\n",
    "ax[1,1].plot(days_of_year,C_daily_R_TP39,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[1,1].plot(days_of_year,S_daily_R_TP39,label='Updated SMUrF',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "l2=ax[1,2].scatter(days_of_year,TPD_daily_R+50,label='TPD Fluxtower',c='k')\n",
    "ax[1,2].plot(days_of_year,TPD_daily_R,label='TPD 2018-2019',c='k')\n",
    "ax[1,2].plot(days_of_year,C_daily_R_TPD,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[1,2].plot(days_of_year,S_daily_R_TPD,label='Updated SMUrF',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[1,0].set_ylabel('R$_{eco}$')\n",
    "\n",
    "ax[2,0].set_ylim(-16,6)\n",
    "ax[2,1].set_ylim(-16,6)\n",
    "ax[2,2].set_ylim(-16,6)\n",
    "\n",
    "ax[2,0].plot(days_of_year,Borden_daily_NEEgf,label='Borden 2018-2020',c='k')\n",
    "ax[2,0].plot(days_of_year,C_daily_NEE,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[2,0].plot(days_of_year,S_daily_NEE,label='Updated SMUrF',c='#FF800E', alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[0,0].set_title('Borden Forest')\n",
    "ax[0,1].set_title('TP39')\n",
    "ax[0,2].set_title('TPD')\n",
    "\n",
    "ax[2,1].plot(days_of_year,TP39_daily_NEEgf,label='TP39 2018-2019',c='k')\n",
    "ax[2,1].plot(days_of_year,C_daily_NEE_TP39,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[2,1].plot(days_of_year,S_daily_NEE_TP39,label='Updated SMUrF',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[2,2].plot(days_of_year,TPD_daily_NEEgf,label='TPD 2018-2019',c='k')\n",
    "ax[2,2].plot(days_of_year,C_daily_NEE_TPD,label='Original SMUrF', c='#006BA4',alpha=0.75)\n",
    "ax[2,2].plot(days_of_year,S_daily_NEE_TPD,label='Updated SMUrF',c='#FF800E',alpha=0.75,linestyle='--')\n",
    "\n",
    "ax[2,0].set_ylabel('NEE')\n",
    "\n",
    "ax[0,1].set_yticks([])\n",
    "ax[0,2].set_yticks([])\n",
    "ax[1,1].set_yticks([])\n",
    "ax[1,2].set_yticks([])\n",
    "ax[2,1].set_yticks([])\n",
    "ax[2,2].set_yticks([])\n",
    "\n",
    "ax[1,0].legend([l0,ls0,ls1],['Flux Tower','Original SMUrF','Updated SMUrF'],loc='upper left',fontsize=16)\n",
    "ax[2,1].set_xlabel('Day of Year')\n",
    "fig.subplots_adjust(hspace=0,wspace=0)\n",
    "# *** Uncomment next two lines to save figure. CHANGE PATHS & FILENAMES ***\n",
    "#plt.savefig('fixed_SMUrF_V061_vs_fixed_fluxtower_Comparison_All_fluxes_2018_larger_font_cb_friendly.pdf',bbox_inches='tight')\n",
    "#plt.savefig('fixed_SMUrF_V061_vs_fixed_fluxtower_Comparison_All_fluxes_2018_larger_font_cb_friendly.png',bbox_inches='tight')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the hourly data over all flux towers \n",
    "All_S_NEE=np.concatenate([S_NEE_Borden,S_NEE_TP39,S_NEE_TPD,S_NEE_2019_TP39,S_NEE_2019_TPD])\n",
    "All_fluxtower_NEE=np.concatenate([Borden_NEE,TP39_NEE,TPD_NEE,TP39_2019_hrly_NEE,TPD_2019_hrly_NEE])\n",
    "All_C_NEE=np.concatenate([C_NEE_array,C_NEE_TP39_array,C_NEE_TPD_array,C_NEE_TP39_2019_array,C_NEE_TPD_2019_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With fluxtower & downscaling fixes\n",
    "finitemask1 = np.isfinite(All_fluxtower_NEE)\n",
    "All_fluxtower_NEEclean0 = All_fluxtower_NEE[finitemask1]\n",
    "All_S_NEEclean0 = All_S_NEE[finitemask1]\n",
    "\n",
    "finitemask2 = np.isfinite(All_S_NEEclean0)\n",
    "Total_S_NEE_2018_2019 = All_S_NEEclean0[finitemask2]\n",
    "Total_fluxtower_S_NEE_2018_2019 = All_fluxtower_NEEclean0[finitemask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With fluxtower fix\n",
    "finitemask1 = np.isfinite(All_fluxtower_NEE)\n",
    "All_fluxtower_NEEclean0 = All_fluxtower_NEE[finitemask1]\n",
    "All_C_NEEclean0 = All_C_NEE[finitemask1]\n",
    "\n",
    "finitemask2 = np.isfinite(All_C_NEEclean0)\n",
    "Total_C_NEE_2018_2019 = All_C_NEEclean0[finitemask2]\n",
    "Total_fluxtower_C_NEE_2018_2019 = All_fluxtower_NEEclean0[finitemask2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Original SMUrF NEE to non-gapfilled flux tower NEE\n",
    "\n",
    "Huber_Tot_C_NEE_slps=[]\n",
    "Huber_Tot_C_NEE_ints=[]\n",
    "Huber_Tot_C_NEE_R2=[]\n",
    "\n",
    "#try bootstrapping\n",
    "indx_list=list(range(0,len(Total_C_NEE_2018_2019)))\n",
    "for i in range(1,1001):\n",
    "    #sub selection of points\n",
    "    NEE_indx=np.random.choice(indx_list,size=len(Total_C_NEE_2018_2019))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((Total_fluxtower_C_NEE_2018_2019[NEE_indx]).reshape(-1,1),Total_C_NEE_2018_2019[NEE_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = Total_fluxtower_C_NEE_2018_2019, Total_C_NEE_2018_2019\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_Tot_C_NEE_slps.append(H_m)\n",
    "        Huber_Tot_C_NEE_ints.append(H_c)\n",
    "        Huber_Tot_C_NEE_R2.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    \n",
    "y_predict = np.nanmean(Huber_Tot_C_NEE_slps) * x_accpt + np.nanmean(Huber_Tot_C_NEE_ints)\n",
    "Huber_C_NEE_R2=r2_score(y_accpt, y_predict)\n",
    "\n",
    "print('Original SMUrF slope: '+str(np.round(np.nanmean(Huber_Tot_C_NEE_slps),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_C_NEE_slps),3)))\n",
    "print('Original SMUrF intercept: '+str(np.round(np.nanmean(Huber_Tot_C_NEE_ints),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_C_NEE_ints),3)))\n",
    "\n",
    "print('Original SMUrF R^2: '+str(np.round(np.nanmean(Huber_C_NEE_R2),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the Updated SMUrF NEE to non-gapfilled flux tower NEE\n",
    "#WITH downscaling, MODIS shift, & fluxtower fixes\n",
    "Huber_Tot_S_NEE_slps=[]\n",
    "Huber_Tot_S_NEE_ints=[]\n",
    "Huber_Tot_S_NEE_R2=[]\n",
    "\n",
    "#try bootstrapping\n",
    "indx_list=list(range(0,len(Total_S_NEE_2018_2019)))\n",
    "for i in range(1,1000):\n",
    "    #sub selection of points\n",
    "    NEE_indx=np.random.choice(indx_list,size=len(Total_S_NEE_2018_2019))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((Total_fluxtower_S_NEE_2018_2019[NEE_indx]).reshape(-1,1),Total_S_NEE_2018_2019[NEE_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = Total_fluxtower_S_NEE_2018_2019, Total_S_NEE_2018_2019\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_Tot_S_NEE_slps.append(H_m)\n",
    "        Huber_Tot_S_NEE_ints.append(H_c)\n",
    "        Huber_Tot_S_NEE_R2.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    \n",
    "y_predict = np.nanmean(Huber_Tot_S_NEE_slps) * x_accpt + np.nanmean(Huber_Tot_S_NEE_ints)\n",
    "Huber_S_NEE_R2=r2_score(y_accpt, y_predict)\n",
    "\n",
    "print('Updated SMUrF slope: '+str(np.round(np.nanmean(Huber_Tot_S_NEE_slps),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_S_NEE_slps),3)))\n",
    "print('Updated SMUrF intercept: '+str(np.round(np.nanmean(Huber_Tot_S_NEE_ints),3))+' +/- '+str(np.round(np.nanstd(Huber_Tot_S_NEE_ints),3)))\n",
    "\n",
    "print('Updated SMUrF R^2: '+str(np.round(np.nanmean(Huber_S_NEE_R2),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('tableau-colorblind10')\n",
    "plt.rc('font',size=18)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlim(-80,20)\n",
    "plt.ylim(-80,20)\n",
    "plt.axis('scaled')\n",
    "\n",
    "plt.scatter(100,100,label='Original SMUrF')\n",
    "plt.scatter(100,100,label='Updated SMUrF')\n",
    "plt.scatter(Total_fluxtower_C_NEE_2018_2019,Total_C_NEE_2018_2019,s=5,c='#006BA4')\n",
    "plt.scatter(Total_fluxtower_S_NEE_2018_2019,Total_S_NEE_2018_2019,s=5,c='#FF800E',alpha=0.5)\n",
    "\n",
    "plt.plot(line1_1,func2(line1_1,np.nanmean(Huber_Tot_C_NEE_slps),np.nanmean(Huber_Tot_C_NEE_ints)),linestyle='--',label=str(np.round(np.nanmean(Huber_Tot_C_NEE_slps),2))+'$\\cdot$x+'+str(np.round(np.nanmean(Huber_Tot_C_NEE_ints),2))+', R$^2$ = '+str(np.round(Huber_C_NEE_R2,2)),c='k', path_effects=[pe.Stroke(linewidth=5, foreground='#006BA4'), pe.Normal()])\n",
    "plt.plot(line1_1,func2(line1_1,np.nanmean(Huber_Tot_S_NEE_slps),np.nanmean(Huber_Tot_S_NEE_ints)),linestyle='-.',label=str(np.round(np.nanmean(Huber_Tot_S_NEE_slps),2))+'$\\cdot$x+'+str(np.round(np.nanmean(Huber_Tot_S_NEE_ints),2))+', R$^2$ = '+str(np.round(Huber_S_NEE_R2,2)),c='k', path_effects=[pe.Stroke(linewidth=5, foreground='#FF800E'), pe.Normal()])\n",
    "\n",
    "plt.plot(line1_1,line1_1,linestyle=':',c='k')\n",
    "plt.title('SMUrF vs Flux Tower NEE')\n",
    "plt.xlabel('Flux Tower NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "plt.ylabel('Modelled NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "plt.legend()\n",
    "# *** Uncomment to save figure. CHANGE FILENAME ***\n",
    "#plt.savefig('fixed_SMUrF_V061_vs_fixed_fluxtower_NEE_non_gapfilled_hrly_fit_Huber_correlation_All_fluxes_2018_2019_larger_font_cb_friendly.pdf',bbox_inches='tight')\n",
    "#plt.savefig('fixed_SMUrF_V061_vs_fixed_fluxtower_NEE_non_gapfilled_hrly_fit_Huber_correlation_All_fluxes_2018_2019_larger_font_cb_friendly.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
