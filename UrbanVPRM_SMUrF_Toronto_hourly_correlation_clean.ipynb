{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to compare the spatial correlation between the updated SMUrF and UrbanVPRM at hourly, daily, monthly,\n",
    "# and annual time scales. We use bootstrapped Hubber fits. Code reproduces figure S4 of Madsen-Colford et al. 2025.\n",
    "# Please cite if code is used.\n",
    "\n",
    "# *** indicates lines (below) that the user should change (e.g. path names etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #numerical python\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from matplotlib.cm import get_cmap #import colour maps for contour plots\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset, date2num #for reading netCDF data files and their date (not sure if I need the later)\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy import optimize as opt \n",
    "from scipy import odr\n",
    "import shapefile as shp # to import outline of GTA\n",
    "from shapely import geometry # used to define a polygon for Toronto\n",
    "from sklearn import linear_model #for doing robust fits\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib.colors as clrs #for log color scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in VPRM data\n",
    "# *** CHANGE PATH *** \n",
    "VPRM_path = 'E:/Research/UrbanVPRM/dataverse_files/GTA_V061_500m_2018/'\n",
    "# *** CHANGE FILE NAME ***\n",
    "VPRM_fn = 'vprm_GMIS_Toronto_ACI_SOLRIS_ISA_500m_GTA_V061_2018_no_PScale_adjusted_Topt_Ra_URB_parameters_fixed_gapfilled_LSWI_filtered_bilinear_PAR_block_'\n",
    "\n",
    "VPRM_data = pd.read_csv(VPRM_path+VPRM_fn+'00000001.csv').loc[:,('HoY','Index','GEE','Re')]\n",
    "\n",
    "VPRM_data2=pd.read_csv(VPRM_path+VPRM_fn+'00002501.csv').loc[:,('HoY','Index','GEE','Re')]\n",
    "VPRM_data=VPRM_data.append(VPRM_data2)\n",
    "del VPRM_data2\n",
    "\n",
    "VPRM_data2=pd.read_csv(VPRM_path+VPRM_fn+'00005001.csv').loc[:,('HoY','Index','GEE','Re')]\n",
    "VPRM_data=VPRM_data.append(VPRM_data2)\n",
    "del VPRM_data2\n",
    "\n",
    "VPRM_data2=pd.read_csv(VPRM_path+VPRM_fn+'00007501.csv').loc[:,('HoY','Index','GEE','Re')]\n",
    "VPRM_data=VPRM_data.append(VPRM_data2)\n",
    "del VPRM_data2\n",
    "\n",
    "VPRM_data2=pd.read_csv(VPRM_path+VPRM_fn+'00010001.csv').loc[:,('HoY','Index','GEE','Re')]\n",
    "VPRM_data=VPRM_data.append(VPRM_data2)\n",
    "del VPRM_data2\n",
    "\n",
    "VPRM_data2=pd.read_csv(VPRM_path+VPRM_fn+'00012501.csv').loc[:,('HoY','Index','GEE','Re')]\n",
    "VPRM_data=VPRM_data.append(VPRM_data2)\n",
    "del VPRM_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** CHANGE FILE NAME ***\n",
    "VPRM_EVI=pd.read_csv(VPRM_path+'adjusted_evi_lswi_interpolated_modis_v061_qc_filtered_LSWI_filtered.csv').loc[:,('Index','x','y')]\n",
    "\n",
    "#Create a dataframe with just Index, x, & y values\n",
    "x=np.zeros(np.shape(VPRM_EVI.Index.unique()))*np.nan\n",
    "y=np.zeros(np.shape(VPRM_EVI.Index.unique()))*np.nan\n",
    "for i in range(len(VPRM_EVI.Index.unique())):\n",
    "    x[i]=VPRM_EVI.x[0+i*365]\n",
    "    y[i]=VPRM_EVI.y[0+i*365]\n",
    "    \n",
    "VPRM_xy=pd.DataFrame({'Index':VPRM_EVI.Index.unique(), 'x':x, 'y':y})\n",
    "VPRM_data=VPRM_data.merge(VPRM_xy[['Index','x','y']])\n",
    "del VPRM_EVI, VPRM_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays of x & y values\n",
    "xvals = VPRM_data.x[VPRM_data.HoY==4800].unique()\n",
    "yvals = VPRM_data.y[VPRM_data.HoY==4800].unique()\n",
    "extent = np.min(xvals), np.max(xvals), np.min(yvals), np.max(yvals)\n",
    "\n",
    "# Reshape GPP and Reco into arrays\n",
    "GPP=-VPRM_data.GEE.values.reshape(len(yvals),len(xvals),8760)#8784 for leap year\n",
    "Reco=VPRM_data.Re.values.reshape(len(yvals),len(xvals),8760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the shape file for Toronto\n",
    "\n",
    "# *** CHANGE PATH ***\n",
    "sf = shp.Reader(\"C:/Users/kitty/Documents/Research/SIF/Shape_files/Toronto/Toronto_Boundary.shp\") #Toronto_Shape\n",
    "shape=sf.shape(0)\n",
    "Toronto_x = np.zeros((len(shape.points),1))*np.nan\n",
    "Toronto_y = np.zeros((len(shape.points),1))*np.nan\n",
    "for i in range(len(shape.points)):\n",
    "    Toronto_x[i]=shape.points[i][0]\n",
    "    Toronto_y[i]=shape.points[i][1]\n",
    "    \n",
    "points=[]\n",
    "for k in range(1,len(Toronto_x)):\n",
    "    points.append(geometry.Point(Toronto_x[k],Toronto_y[k]))\n",
    "poly=geometry.Polygon([[p.x, p.y] for p in points])\n",
    "\n",
    "#Create a mask for areas outside Toronto\n",
    "lons=np.ones(144)*np.nan\n",
    "lats=np.ones(96)*np.nan\n",
    "GPP_mask=np.ones([96,144])*np.nan\n",
    "for i in range(0, len(lons)):\n",
    "    for j in range(0, len(lats)):\n",
    "        lons[i]=xvals[i]\n",
    "        lats[j]=yvals[j]\n",
    "        if poly.contains(geometry.Point([xvals[i],yvals[j]])):\n",
    "            GPP_mask[j,i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Toronto mask to GPP & Reco & compute NEE\n",
    "T_VPRM_GPP=GPP*GPP_mask[:,:,np.newaxis]\n",
    "T_VPRM_Reco=Reco*GPP_mask[:,:,np.newaxis]\n",
    "T_VPRM_NEE=T_VPRM_Reco-T_VPRM_GPP\n",
    "\n",
    "#swap the axes to match those of SMUrF\n",
    "T_VPRM_NEE=np.swapaxes(np.swapaxes(T_VPRM_NEE,0,2),1,2)\n",
    "del T_VPRM_GPP, T_VPRM_Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now bring in the SMUrF data with ISA adjustment, shoreline correction, AND downscaling fix\n",
    "\n",
    "# Bring in the first Reco file and extract the first day of the year (in seconds since 1970)\n",
    "# ***CHANGE PATH AND FILE NAME ***\n",
    "g=Dataset('C:/Users/kitty/Documents/Research/SIF/SMUrF/output2018_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_V3_temp_impervious_R_shore_corr_V061_8day/easternCONUS/daily_mean_Reco_ISA_a_neuralnet/era5/2018/daily_mean_Reco_uncert_GMIS_Toronto_t_easternCONUS_20180101.nc')\n",
    "start_of_year=g.variables['time'][0]/3600/24-1 #convert seconds since 1970 to days (minus one)\n",
    "g.close()\n",
    "\n",
    "\n",
    "#Load in SMUrF NEE data\n",
    "# *** CHANGE PATH ***\n",
    "SMUrF_path = 'E:/Research/SMUrF/output2018_500m_CSIF_to_TROPOMI_CSIF_ALL_converted_slps_V3_temp_impervious_R_shore_corr_V061_8day/easternCONUS/hourly_flux_GMIS_Toronto_fixed_border_ISA_a_w_sd_era5/'\n",
    "# *** CHANGE FILE NAME ***\n",
    "SMUrF_fn = 'hrly_mean_GPP_Reco_NEE_easternCONUS_2018'\n",
    "\n",
    "S_time=[]\n",
    "S_NEE=[]\n",
    "S_lats=[]\n",
    "S_lons=[]\n",
    "for j in range(1,13): # *** ADJUST THIS TO USE SPECIFIC MONTHS ***\n",
    "    try:\n",
    "        if j<10:\n",
    "            f=Dataset(SMUrF_path+SMUrF_fn+'0'+str(j)+'.nc')\n",
    "        else:\n",
    "            f=Dataset(SMUrF_path+SMUrF_fn+str(j)+'.nc')\n",
    "        if len(S_time)==0:\n",
    "            S_lats=f.variables['lat'][:]\n",
    "            S_lons=f.variables['lon'][:]\n",
    "            S_NEE=f.variables['NEE_mean'][:,264:360,288:432]\n",
    "            S_time=f.variables['time'][:]/24/3600-start_of_year-5/24 #convert seconds since 1970 to days and subtract start of year\n",
    "        else:\n",
    "            S_NEE=np.concatenate((S_NEE,f.variables['NEE_mean'][:,264:360,288:432]),axis=0)\n",
    "            S_time=np.concatenate((S_time,(f.variables['time'][:]/24/3600-start_of_year-5/24)),axis=0)\n",
    "        f.close()\n",
    "    except FileNotFoundError:\n",
    "        print(j)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace fill values with NaN\n",
    "S_NEE[S_NEE==-999]=np.nan\n",
    "\n",
    "# Apply Toronto mask\n",
    "T_S_NEE=S_NEE[:,::-1]*GPP_mask[np.newaxis,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del S_NEE, VPRM_data, GPP, Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function and straight line for fitting and plotting\n",
    "\n",
    "def func2(x,m,b):\n",
    "    return m*x+b\n",
    "\n",
    "line1_1=np.arange(-100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the hourly data with a 1000x bootstrapped Huber fit\n",
    "\n",
    "# WITH Shoreline and ISA correction\n",
    "finitemask0=np.isfinite(T_S_NEE) & np.isfinite(T_VPRM_NEE)\n",
    "T_S_NEE_clean0=T_S_NEE[finitemask0]\n",
    "T_VPRM_NEE_clean0=T_VPRM_NEE[finitemask0]\n",
    "\n",
    "Huber_2018_slps=[]\n",
    "Huber_2018_ints=[]\n",
    "Huber_2018_R2=[]\n",
    "\n",
    "#try bootstrapping\n",
    "indx_list=list(range(0,len(T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)])))\n",
    "for i in range(1,1001):\n",
    "    #sub selection of points\n",
    "    S_NEE_indx=np.random.choice(indx_list,size=int(50000))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)][S_NEE_indx]).reshape(-1,1),T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)][S_NEE_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        y_predict = H_m * T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)] + H_c\n",
    "        H_R2=r2_score(T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)], y_predict)\n",
    "        Huber_2018_slps.append(H_m)\n",
    "        Huber_2018_ints.append(H_c)\n",
    "        Huber_2018_R2.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    \n",
    "    if int(i)%10==0: #This line prints progress in %, can comment out if desired\n",
    "        print(i/1000*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 using the average slope and intercept from the bootstrapped Huber fits\n",
    "Huber_avg_R2=r2_score(T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)], T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)]*np.nanmean(Huber_2018_slps)+np.nanmean(Huber_2018_ints))\n",
    "print('Hourly Huber fit R^2 = '+str(np.round(Huber_avg_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 assuming a 1:1 correlation\n",
    "NEE_2018_slope1_R2=r2_score(T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)], T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)])\n",
    "print('Hourly fit 1:1 line R^2 = '+str(np.round(NEE_2018_slope1_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check (calculate 1:1 R2 by hand)\n",
    "#sum_tot = np.sum((T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)]-np.mean(T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)]))**2)\n",
    "#sum_res= np.sum((T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)]-func2(T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)],1,0))**2)\n",
    "#print(1-sum_res/sum_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Optional: Uncomment to plot correlation of hourly data ***\n",
    "\n",
    "#plt.style.use('tableau-colorblind10')\n",
    "\n",
    "#plt.figure(figsize=(8,6))\n",
    "#plt.xlim(-20,7)\n",
    "#plt.ylim(-20,7)\n",
    "#plt.axis('scaled')\n",
    "#plt.scatter(T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)][S_NEE_indx],T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)][S_NEE_indx],alpha=0.1,s=5)\n",
    "#plt.plot(line1_1,line1_1*np.nanmean(Huber_2018_slps)+np.nanmean(Huber_2018_ints),label=str(np.round(np.nanmean(Huber_2018_slps),2))+'$\\cdot$x + '+str(np.round(np.nanmean(Huber_2018_ints),2))+', R$^2$ = '+str(np.round(Huber_avg_R2,2)),linestyle='--',c='#FF800E')\n",
    "#plt.plot(line1_1,line1_1,linestyle='-.',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_slope1_R2,2)))\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.ylabel('UrbanVPRM NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('SMUrF vs. UrbanVPRM NEE over Toronto, 2018')\n",
    "##*** Uncomment to save figure as png & pdf CHANGE FILENAME ***\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_hourly_bootstrap_Huber_correlation_no_weights_subselection.pdf',bbox_inches='tight')\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_hourly_bootstrap_Huber_correlation_no_weights_subselection.png',bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily average NEE for SMUrF and UrbanVPRM\n",
    "VPRM_NEE_daily=np.ones((365, 96, 144))*np.nan\n",
    "S_NEE_daily=np.ones((365, 96, 144))*np.nan\n",
    "for i in range(365):\n",
    "    VPRM_NEE_daily[i]=np.nanmean(T_VPRM_NEE[i*24:i*24+24],axis=0)\n",
    "    S_NEE_daily[i]=np.nanmean(T_S_NEE[i*24:i*24+24],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply 1000x bootstrapped Huber fit to daily average NEE\n",
    "\n",
    "# WITH Shoreline and ISA correction\n",
    "finitemask0=np.isfinite(S_NEE_daily) & np.isfinite(VPRM_NEE_daily) & (S_NEE_daily!=0) & (VPRM_NEE_daily!=0)\n",
    "S_NEE_daily_clean0=S_NEE_daily[finitemask0]\n",
    "VPRM_NEE_daily_clean0=VPRM_NEE_daily[finitemask0]\n",
    "\n",
    "Huber_dly_slps=[]\n",
    "Huber_dly_ints=[]\n",
    "Huber_dly_R2=[]\n",
    "\n",
    "#try bootstrapping\n",
    "dly_indx_list=list(range(0,len(S_NEE_daily_clean0)))\n",
    "for i in range(1,1000):\n",
    "    #sub selection of points\n",
    "    S_NEE_dly_indx=np.random.choice(dly_indx_list,size=int(50000))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((S_NEE_daily_clean0[S_NEE_dly_indx]).reshape(-1,1),VPRM_NEE_daily_clean0[S_NEE_dly_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = S_NEE_daily_clean0,VPRM_NEE_daily_clean0\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_dly_slps.append(H_m)\n",
    "        Huber_dly_ints.append(H_c)\n",
    "        Huber_dly_R2.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    if int(i)%10==0:\n",
    "        print(i/1000*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 using the average slope and intercept from the bootstrapped Huber fits\n",
    "Huber_dly_avg_R2=r2_score(VPRM_NEE_daily_clean0, S_NEE_daily_clean0*np.nanmean(Huber_dly_slps)+np.nanmean(Huber_dly_ints))\n",
    "#Huber_dly_avg_R2\n",
    "print('Daily Average Huber fit R^2 = '+str(np.round(Huber_dly_avg_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 assuming 1:1 correlation\n",
    "NEE_2018_daily_slope1_R2=r2_score(VPRM_NEE_daily_clean0, S_NEE_daily_clean0)\n",
    "#NEE_2018_daily_slope1_R2\n",
    "print('Daily average fit 1:1 R^2 = '+str(np.round(NEE_2018_daily_slope1_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check (calculate 1:1 R2 by hand)\n",
    "#sum_tot = np.sum((VPRM_NEE_daily_clean0-np.mean(VPRM_NEE_daily_clean0))**2)\n",
    "#sum_res= np.sum((VPRM_NEE_daily_clean0-func2(S_NEE_daily_clean0,1,0))**2)\n",
    "#print(1-sum_res/sum_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Optional: Uncomment to plot correlation of daily-averaged data ***\n",
    "\n",
    "##50000 points (3.4% of data)\n",
    "#plt.rc('font',size=14)\n",
    "\n",
    "#plt.figure(figsize=(6,8))\n",
    "#plt.xlim(-35,8)\n",
    "#plt.ylim(-35,8)\n",
    "#plt.axis('scaled')\n",
    "#plt.scatter(S_NEE_daily_clean0[S_NEE_dly_indx],VPRM_NEE_daily_clean0[S_NEE_dly_indx],s=1)\n",
    "#plt.plot(line1_1,line1_1*np.nanmean(Huber_dly_slps)+np.nanmean(Huber_dly_ints),linewidth=2,linestyle='--',label=str(np.round(np.nanmean(Huber_dly_slps),2))+'x + '+str(np.round(np.nanmean(Huber_dly_ints),2))+', R$^2$ = '+str(np.round(Huber_dly_avg_R2,2)),c='#FF800E')\n",
    "#plt.plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_daily_slope1_R2,2)))\n",
    "#plt.legend()\n",
    "#plt.xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.ylabel('UrbanVPRM NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('SMUrF vs. UrbanVPRM Daily NEE, Toronto, 2018')\n",
    "##*** Uncomment to save figure as png and pdf. CHANGE FILENAME ***\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_daily_Huber_no_errs_correlation_subselection.pdf',bbox_inches='tight')\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_daily_Huber_no_errs_correlation_subselection.png',bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 30 day average of SMUrF and VPRM NEE\n",
    "VPRM_NEE_30d=np.ones((12, 96, 144))*np.nan\n",
    "S_NEE_30d=np.ones((12, 96, 144))*np.nan\n",
    "for i in range(12):\n",
    "    VPRM_NEE_30d[i]=np.nanmean(T_VPRM_NEE[i*30*24:i*30*24+30*24],axis=0)\n",
    "    S_NEE_30d[i]=np.nanmean(T_S_NEE[i*30*24:i*30*24+30*24],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply 1000x bootstrapped Huber fit to monthly averaged data\n",
    "finitemask0=np.isfinite(S_NEE_30d) & np.isfinite(VPRM_NEE_30d) & (S_NEE_30d!=0)\n",
    "S_NEE_30d_clean0=S_NEE_30d[finitemask0]\n",
    "VPRM_NEE_30d_clean0=VPRM_NEE_30d[finitemask0]\n",
    "\n",
    "Huber_30d_slps=[]\n",
    "Huber_30d_ints=[]\n",
    "Huber_30d_R2=[]\n",
    "\n",
    "#try bootstrapping\n",
    "indx_30d_list=list(range(0,len(S_NEE_30d_clean0)))\n",
    "for i in range(1,1000):\n",
    "    #sub selection of points\n",
    "    S_NEE_30d_indx=np.random.choice(indx_30d_list,size=int(50000))\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((S_NEE_30d_clean0[S_NEE_30d_indx]).reshape(-1,1),VPRM_NEE_30d_clean0[S_NEE_30d_indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = S_NEE_30d_clean0, VPRM_NEE_30d_clean0\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_30d_slps.append(H_m)\n",
    "        Huber_30d_ints.append(H_c)\n",
    "        Huber_30d_R2.append(H_R2)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if int(i)%10==0:\n",
    "        print(i/1000*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 using the average Huber fit\n",
    "Huber_30d_avg_R2=r2_score(VPRM_NEE_30d_clean0,S_NEE_30d_clean0*np.nanmean(Huber_30d_slps)+np.nanmean(Huber_30d_ints))\n",
    "#Huber_30d_avg_R2\n",
    "print('30-day average Huber fit R^2 = '+str(np.round(Huber_30d_avg_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 assuming a 1:1 correlation\n",
    "NEE_2018_30d_slope1_R2=r2_score(VPRM_NEE_30d_clean0,S_NEE_30d_clean0)\n",
    "#NEE_2018_30d_slope1_R2\n",
    "print('30-day average fit 1:1 R^2 = '+str(np.round(NEE_2018_30d_slope1_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sanity check (calculate 1:1 R2 by hand)\n",
    "#sum_tot = np.sum((VPRM_NEE_30d_clean0-np.mean(VPRM_NEE_30d_clean0))**2)\n",
    "#sum_res= np.sum((VPRM_NEE_30d_clean0-func2(S_NEE_30d_clean0,1,0))**2)\n",
    "#print(1-sum_res/sum_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Optional: Uncomment to plot correlation of 30day averaged data ***\n",
    "\n",
    "#Bootstrapped Huber fit\n",
    "#all points\n",
    "#plt.rc('font',size=14)\n",
    "\n",
    "#plt.figure(figsize=(8,6))\n",
    "#plt.xlim(-15,5)\n",
    "#plt.ylim(-15,5)\n",
    "#plt.axis('scaled')\n",
    "#plt.scatter(S_NEE_30d_clean0,VPRM_NEE_30d_clean0,s=1,alpha=0.25)\n",
    "#plt.plot(line1_1,line1_1*np.nanmean(Huber_30d_slps)+np.nanmean(Huber_30d_ints),linestyle='--',label=str(np.round(np.nanmean(Huber_30d_slps),2))+'x + '+str(np.round(np.nanmean(Huber_30d_ints),2))+', R$^2$ = '+str(np.round(Huber_30d_avg_R2,2)),c='#FF800E')\n",
    "#plt.plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_30d_slope1_R2,2)))\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.ylabel('UrbanVPRM NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('SMUrF vs. UrbanVPRM 30d avg NEE, Toronto')\n",
    "## *** Uncomment to save figure as png and pdf. CHANGE FILENAMES ***\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_30d_Huber_no_errs_correlation_subselection.pdf',bbox_inches='tight')\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_30d_Huber_no_errs_correlation_subselection.png',bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the annual average of SMUrF and UrbanVPRM NEE data over Toronto\n",
    "VPRM_NEE_2018_avg=np.nanmean(T_VPRM_NEE,axis=0)\n",
    "S_NEE_2018_avg=np.nanmean(T_S_NEE,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a 1000x bootstrapped Huber fit to the annual Toronto NEE data\n",
    "finitemask0=np.isfinite(S_NEE_2018_avg) & np.isfinite(VPRM_NEE_2018_avg)\n",
    "S_NEE_2018_avg_clean0=S_NEE_2018_avg[finitemask0]\n",
    "VPRM_NEE_2018_avg_clean0=VPRM_NEE_2018_avg[finitemask0]\n",
    "\n",
    "Huber_2018_avg_slps=[]\n",
    "Huber_2018_avg_ints=[]\n",
    "Huber_2018_avg_R2=[]\n",
    "\n",
    "#try bootstrapping\n",
    "indx_2018_avg_list=list(range(0,len(S_NEE_2018_avg_clean0)))\n",
    "for i in range(1,1000):\n",
    "    #sub selection of points\n",
    "    S_NEE_2018_avg_indx=np.random.choice(indx_2018_avg_list,size=len(indx_2018_avg_list))\n",
    "    \n",
    "    Huber_model = linear_model.HuberRegressor()\n",
    "    Huber_fit=Huber_model.fit((S_NEE_2018_avg_clean0[S_NEE_2018_avg_indx]).reshape(-1,1),VPRM_NEE_2018_avg_clean0[S_NEE_2018_avg_indx])\n",
    "    H_m=Huber_fit.coef_\n",
    "    H_c=Huber_fit.intercept_\n",
    "    x_accpt, y_accpt = S_NEE_2018_avg_clean0, VPRM_NEE_2018_avg_clean0\n",
    "    y_predict = H_m * x_accpt + H_c\n",
    "    H_R2=r2_score(y_accpt, y_predict)\n",
    "    Huber_2018_avg_slps.append(H_m)\n",
    "    Huber_2018_avg_ints.append(H_c)\n",
    "    Huber_2018_avg_R2.append(H_R2)\n",
    "    if int(i)%100==0:\n",
    "        print(i/1000*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute R2 using average Huber fit for annual data\n",
    "Huber_ann_R2=r2_score(VPRM_NEE_2018_avg_clean0[(S_NEE_2018_avg_clean0!=0) & (VPRM_NEE_2018_avg_clean0!=0)],S_NEE_2018_avg_clean0[(S_NEE_2018_avg_clean0!=0) & (VPRM_NEE_2018_avg_clean0!=0)]*np.nanmean(Huber_2018_avg_slps)+np.nanmean(Huber_2018_avg_ints))\n",
    "#Huber_ann_R2\n",
    "print('Annual average Huber fit R^2 = '+str(np.round(Huber_ann_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute R2 using average Huber fit for annual data\n",
    "NEE_2018_avg_slope1_R2=r2_score(VPRM_NEE_2018_avg_clean0,S_NEE_2018_avg_clean0)\n",
    "#NEE_2018_avg_slope1_R2\n",
    "print('Annual average fit 1:1 R^2 = '+str(np.round(NEE_2018_avg_slope1_R2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check (calculate 1:1 R2 by hand)\n",
    "#sum_tot = np.sum((VPRM_NEE_2018_avg_clean0-np.mean(VPRM_NEE_2018_avg_clean0))**2)\n",
    "#sum_res= np.sum((VPRM_NEE_2018_avg_clean0-func2(S_NEE_2018_avg_clean0,1,0))**2)\n",
    "#print(1-sum_res/sum_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Optional: Uncomment to plot correlation of annual-averaged data ***\n",
    "##all points\n",
    "#plt.rc('font',size=14)\n",
    "\n",
    "#plt.figure(figsize=(8,6))\n",
    "#plt.xlim(-3,1)\n",
    "#plt.ylim(-3,1)\n",
    "#plt.axis('scaled')\n",
    "#plt.scatter(S_NEE_2018_avg_clean0[(S_NEE_2018_avg_clean0!=0) & (VPRM_NEE_2018_avg_clean0!=0)],VPRM_NEE_2018_avg_clean0[(S_NEE_2018_avg_clean0!=0) & (VPRM_NEE_2018_avg_clean0!=0)],s=1)\n",
    "#plt.plot(line1_1,line1_1*np.nanmean(Huber_2018_avg_slps)+np.nanmean(Huber_2018_avg_ints),linestyle='--',label=str(np.round(np.nanmean(Huber_2018_avg_slps),2))+'x + '+str(np.round(np.nanmean(Huber_2018_avg_ints),2))+', R$^2$ = '+str(np.round(Huber_ann_R2,2)),c='#FF800E')\n",
    "#plt.plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_avg_slope1_R2,2)))\n",
    "#plt.legend(loc='lower right')\n",
    "#plt.xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.ylabel('UrbanVPRM NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "#plt.title('SMUrF vs. UrbanVPRM 2018 Average NEE, Toronto')\n",
    "## *** Uncomment to save figure as png and pdf. CHANGE FILENAME ***\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_2018_avg_Huber_no_errs_correlation.pdf',bbox_inches='tight')\n",
    "#plt.savefig('Toronto_Fixed_SMUrF_vs_UrbanVPRM_NEE_2018_avg_Huber_no_errs_correlation.png',bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font',size=24)\n",
    "\n",
    "fig, ax = plt.subplots(2,2,sharex=True,sharey=True,figsize=(16,16))\n",
    "ax[0,0].set_xlim(-25,8)\n",
    "ax[0,0].set_ylim(-25,8)\n",
    "\n",
    "ax[0,0].scatter(T_S_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)][S_NEE_indx],T_VPRM_NEE_clean0[(T_S_NEE_clean0!=0) & (T_VPRM_NEE_clean0!=0)][S_NEE_indx],s=1)\n",
    "ax[0,0].plot(line1_1,line1_1*np.nanmean(Huber_2018_slps)+np.nanmean(Huber_2018_ints),linewidth=2,linestyle='--',label=str(np.round(np.nanmean(Huber_2018_slps),2))+'x + '+str(np.round(np.nanmean(Huber_2018_ints),2))+', R$^2$ = '+str(np.round(Huber_avg_R2,2)),c='#FF800E')\n",
    "ax[0,0].plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_slope1_R2,2)))\n",
    "ax[0,0].legend(loc=(0.205,0.12),fontsize=22)\n",
    "ax[0,0].set_xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "ax[0,0].set_ylabel('UrbanVPRM NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "ax[0,0].set_title('Hourly NEE')\n",
    "\n",
    "ax[0,1].scatter(S_NEE_daily_clean0[(S_NEE_daily_clean0!=0) & (VPRM_NEE_daily_clean0!=0)][S_NEE_dly_indx],VPRM_NEE_daily_clean0[(S_NEE_daily_clean0!=0) & (VPRM_NEE_daily_clean0!=0)][S_NEE_dly_indx],s=1)\n",
    "ax[0,1].plot(line1_1,line1_1*np.nanmean(Huber_dly_slps)+np.nanmean(Huber_dly_ints),linewidth=2,linestyle='--',label=str(np.round(np.nanmean(Huber_dly_slps),2))+'x + '+str(np.round(np.nanmean(Huber_dly_ints),2))+', R$^2$ = '+str(np.round(Huber_dly_avg_R2,2)),c='#FF800E')\n",
    "\n",
    "ax[0,1].plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_daily_slope1_R2,2)))\n",
    "ax[0,1].legend(loc=(0.205,0.12),fontsize=22)\n",
    "ax[0,1].set_xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "ax[0,1].set_title('Daily Average NEE')\n",
    "\n",
    "ax[1,0].scatter(S_NEE_30d_clean0[(S_NEE_30d_clean0!=0) & (VPRM_NEE_30d_clean0!=0)][S_NEE_30d_indx],VPRM_NEE_30d_clean0[(S_NEE_30d_clean0!=0) & (VPRM_NEE_30d_clean0!=0)][S_NEE_30d_indx],s=1)\n",
    "ax[1,0].plot(line1_1,line1_1*np.nanmean(Huber_30d_slps)+np.nanmean(Huber_30d_ints),linewidth=2,linestyle='--',label=str(np.round(np.nanmean(Huber_30d_slps),2))+'x + '+str(np.round(np.nanmean(Huber_30d_ints),2))+', R$^2$ = '+str(np.round(Huber_30d_avg_R2,2)),c='#FF800E')\n",
    "\n",
    "ax[1,0].plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_30d_slope1_R2,2)))\n",
    "ax[1,0].legend(loc='lower right',fontsize=22)\n",
    "ax[1,0].set_ylabel('UrbanVPRM NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "ax[1,0].set_xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "ax[1,0].set_title('Monthly Average NEE')\n",
    "\n",
    "ax[1,1].scatter(S_NEE_2018_avg_clean0[(S_NEE_2018_avg_clean0!=0) & (VPRM_NEE_2018_avg_clean0!=0)],VPRM_NEE_2018_avg_clean0[(S_NEE_2018_avg_clean0!=0) & (VPRM_NEE_2018_avg_clean0!=0)],s=1)\n",
    "ax[1,1].plot(line1_1,line1_1*np.nanmean(Huber_2018_avg_slps)+np.nanmean(Huber_2018_avg_ints),linestyle='--',label=str(np.round(np.nanmean(Huber_2018_avg_slps),2))+'x - '+str(np.round(-np.nanmean(Huber_2018_avg_ints),2))+', R$^2$ = '+str(np.round(Huber_ann_R2,2)),c='#FF800E')\n",
    "ax[1,1].plot(line1_1,line1_1,linestyle=':',c='k',label='1:1, R$^2$ = '+str(np.round(NEE_2018_avg_slope1_R2,2)))\n",
    "ax[1,1].legend(loc='lower right',fontsize=22)\n",
    "ax[1,1].set_xlabel('SMUrF NEE ($\\mu$mol m$^{-2}$ s$^{-1}$)')\n",
    "ax[1,1].set_title('Annual Average NEE')\n",
    "\n",
    "ax[0,0].text(-24.5,6,'(a)',c='k',fontsize=24)\n",
    "ax[0,1].text(-24.5,6,'(b)',c='k',fontsize=24)\n",
    "ax[1,0].text(-24.5,6,'(c)',c='k',fontsize=24)\n",
    "ax[1,1].text(-24.5,6,'(d)',c='k',fontsize=24)\n",
    "\n",
    "fig.subplots_adjust(hspace=0,wspace=0)\n",
    "# Uncomment to save figures as .png and .pdf *** CHANGE PATHS & FILENAMES ***\n",
    "plt.savefig('Toronto_Fixed_SMUrF_UrbanVPRM_NEE_Huber_correlation_hrly_dly_30d_annual_less_data_labelled.pdf',bbox_inches='tight')\n",
    "plt.savefig('Toronto_Fixed_SMUrF_UrbanVPRM_NEE_Huber_correlation_hrly_dly_30d_annual_less_data_labelled.png',bbox_inches='tight')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
