{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to directly compare the Contiguous Solar-Induced Fluorescence (CSIF) product, downscaled using the\n",
    "# Near Infrared Reflectance Vegetation index (NIRv) from MODIS, to downscaled SIF from the TROPOMI instrument, using a\n",
    "# bootstrapped Huber fit. We see a strong correlation between the two products.\n",
    "\n",
    "# This code creates figure S1 of Madsen-Colford et al. 2025\n",
    "# If used, please cite\n",
    "\n",
    "# Comments labelled with *** are areas that should be changed by the user (e.g. change directory paths, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required packages\n",
    "import numpy as np #numerical python\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "from matplotlib.cm import get_cmap #import colour maps for contour plots\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset, date2num #for reading netCDF data files and their date (not sure if I need the later)\n",
    "import time #for timing how long a computation takes\n",
    "import shapefile as shp # to import outline of GTA\n",
    "from shapely import geometry # used to define boundaries of TROPOMI pixels\n",
    "import glob\n",
    "from pyhdf.SD import SD, SDC #Used for reading MODIS hdf files to a format usable by Python\n",
    "from scipy import optimize as opt \n",
    "from scipy import odr\n",
    "from sklearn import linear_model #for robust fitting\n",
    "from sklearn.metrics import r2_score, mean_squared_error #for analyzing robust fits\n",
    "import matplotlib.colors as clrs #for log color scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in TROPOMI SIF data over the for the GTA:\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "sif_path = '/export/data2/downscaled_SIF/downscaled_TROPOSIF/2018/'\n",
    "sif_fn = 'downscaled_sif_V061_filtered_fixed_os_ds_2018_8d_buff_' #filename WITHOUT day of year\n",
    "\n",
    "TROPO_sif_err=np.zeros([46,553,625])*np.nan\n",
    "TROPO_sif_data=np.zeros([46,553,625])*np.nan\n",
    "TROPO_sif_date=np.zeros([46])*np.nan\n",
    "time=4\n",
    "for i in range(1,365,8):\n",
    "    try:\n",
    "        if i<10:\n",
    "            f=Dataset(sif_path+sif_fn+'00'+str(i)+'.nc')\n",
    "        elif i<100:\n",
    "            f=Dataset(sif_path+sif_fn+'0'+str(i)+'.nc')\n",
    "        else:\n",
    "            f=Dataset(sif_path+sif_fn+str(i)+'.nc')\n",
    "        TROPO_sif_data[np.int((i-1)/8)]=f.variables['daily_sif'][:]\n",
    "        TROPO_sif_err[np.int((i-1)/8)]=f.variables['Errors'][:]\n",
    "        TROPO_sif_date[np.int((i-1)/8)]=time \n",
    "        f.close()\n",
    "    except FileNotFoundError and OSError:\n",
    "        pass\n",
    "    time+=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=Dataset(sif_path+sif_fn+'225.nc')\n",
    "lons=f.variables['lon'][:]\n",
    "lats=f.variables['lat'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in 2018's downscaled CSIF data for the GTA:\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "CSIF_path = '/export/data2/downscaled_SIF/downscaled_CSIF/2018/'\n",
    "CSIF_fn = 'downscaled_CSIF_V061_fixed_os_ds_2018_8d_buff_'\n",
    "\n",
    "CSIF_data=np.zeros([46,len(lats),len(lons)])*np.nan\n",
    "CSIF_date=np.zeros([46])*np.nan\n",
    "time=4\n",
    "for i in range(1,367,8):\n",
    "    try:\n",
    "        if i<10:\n",
    "            # *** Change Path ***\n",
    "            f=Dataset(CSIF_path+CSIF_fn+'00'+str(i)+'.nc')\n",
    "        elif i<100:\n",
    "            # *** Change Path ***\n",
    "            f=Dataset(CSIF_path+CSIF_fn+'0'+str(i)+'.nc')\n",
    "        else:\n",
    "            # *** Change Path ***\n",
    "            f=Dataset(CSIF_path+CSIF_fn+str(i)+'.nc')\n",
    "        CSIF_data[np.int((i-1)/8)]=f.variables['daily_sif'][:]\n",
    "        CSIF_date[np.int((i-1)/8)]=time \n",
    "        f.close()\n",
    "    except FileNotFoundError and OSError:\n",
    "        pass\n",
    "    time+=8\n",
    "    \n",
    "# load in lats & lons from one of the files\n",
    "f=Dataset(CSIF_path+CSIF_fn+'121.nc')\n",
    "CSIF_lons=f.variables['lon'][:]\n",
    "CSIF_lats=f.variables['lat'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove erroneous downscaled TROPOMI SIF data\n",
    "with np.errstate(invalid='ignore'):\n",
    "    TROPO_sif_data[TROPO_sif_data>100]=np.nan\n",
    "    TROPO_sif_err[TROPO_sif_err==0]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in landcover data\n",
    "\n",
    "# *** CHANGE PATH & FILENAME ***\n",
    "mod_land_data=Dataset('/export/data/analysis/tropomi/sif/downscaled/2018/MODIS_Land_Type.nc')\n",
    "Land_Data=mod_land_data.variables['Land_Type'][:]\n",
    "Land_Edge=mod_land_data.variables['Edge_Land_Type'][:]\n",
    "mod_land_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate data into different land cover types\n",
    "\n",
    "CSIF_Rural=np.ones(np.shape(CSIF_data))*np.nan\n",
    "CSIF_Crops=np.ones(np.shape(CSIF_data))*np.nan\n",
    "CSIF_Urban=np.ones(np.shape(CSIF_data))*np.nan\n",
    "for i in range(len(TROPO_sif_date)):\n",
    "    CSIF_Rural[i][::-1][Land_Data.T<12]=CSIF_data[i][::-1][Land_Data.T<12]\n",
    "    CSIF_Crops[i][::-1][(Land_Data.T==12) | (Land_Data.T==14)]=CSIF_data[i][::-1][(Land_Data.T==12) | (Land_Data.T==14)]\n",
    "    CSIF_Urban[i][::-1][Land_Data.T==13]=CSIF_data[i][::-1][Land_Data.T==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a straight line & linear function for fitting & plotting\n",
    "\n",
    "line1_1=np.arange(-5,5)\n",
    "\n",
    "def func2(x,m,b):\n",
    "    return m*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_array=np.ones(np.shape(TROPO_sif_data))\n",
    "for i in range(len(CSIF_date)):\n",
    "    date_array[i]=CSIF_date[i]*date_array[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSIF has been shown to understimate SIF in urban areas by 14.5%, \n",
    "# Correct for this by multiplying by 1.145\n",
    "Adjusted_CSIF=np.copy(CSIF_data)\n",
    "Adjusted_CSIF[i][::-1][Land_Data.T==13]=CSIF_data[i][::-1][Land_Data.T==13]*1.145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply a 1000 times bootstrapped Huber fit between downscaled TROPOMI SIF\n",
    "# and downscaled CSIF data\n",
    "\n",
    "# remove non-finite data\n",
    "finitemask1 = np.isfinite(TROPO_sif_data)\n",
    "TROPO_clean0 = TROPO_sif_data[finitemask1]\n",
    "TROPO_err_clean0 = TROPO_sif_err[finitemask1]\n",
    "Adjusted_CSIF_clean0 = Adjusted_CSIF[finitemask1]\n",
    "dates_clean0=date_array[finitemask1]\n",
    "\n",
    "finitemask2 = np.isfinite(Adjusted_CSIF_clean0)\n",
    "TROPO_clean = TROPO_clean0[finitemask2]\n",
    "TROPO_err_clean = TROPO_err_clean0[finitemask2]\n",
    "Adjusted_CSIF_clean = Adjusted_CSIF_clean0[finitemask2]\n",
    "dates_clean = dates_clean0[finitemask2]\n",
    "\n",
    "Huber_slps=[]\n",
    "Huber_ints=[]\n",
    "Huber_R2s=[]\n",
    "\n",
    "#try bootstrapping\n",
    "indx_list=list(range(0,len(Adjusted_CSIF_clean)))\n",
    "for i in range(1,1001):\n",
    "    #sub selection of points\n",
    "    indx=np.random.choice(indx_list,size=50000)\n",
    "    \n",
    "    try:\n",
    "        Huber_model = linear_model.HuberRegressor(fit_intercept=True)\n",
    "        Huber_fit=Huber_model.fit((TROPO_clean[indx]).reshape(-1,1),Adjusted_CSIF_clean[indx])\n",
    "        H_m=Huber_fit.coef_\n",
    "        H_c=Huber_fit.intercept_\n",
    "        x_accpt, y_accpt = TROPO_clean, Adjusted_CSIF_clean\n",
    "        y_predict = H_m * x_accpt + H_c\n",
    "        H_R2=r2_score(y_accpt, y_predict)\n",
    "        Huber_slps.append(H_m)\n",
    "        Huber_ints.append(H_c)\n",
    "        Huber_R2s.append(H_R2)\n",
    "    except ValueError: #if Huber fit can't find a solution for the subset, skip it\n",
    "        pass\n",
    "    \n",
    "y_predict = np.nanmean(Huber_slps) * x_accpt + np.nanmean(Huber_ints)\n",
    "Huber_R2=r2_score(y_accpt, y_predict)\n",
    "print('Huber fit slope = '+str(np.round(np.nanmean(Huber_slps),4))+' +/- '+str(np.round(np.nanstd(Huber_slps),4)))\n",
    "print('Huber fit intercept = '+str(np.round(np.nanmean(Huber_ints),4))+' +/- '+str(np.round(np.nanstd(Huber_ints),4)))\n",
    "print('Huber fit R2 = '+str(np.round(Huber_R2,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R2 of 1 to 1 line\n",
    "R2_1_1=r2_score(Adjusted_CSIF_clean,TROPO_clean)\n",
    "print('1 to 1 line R2 = '+str(np.round(R2_1_1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of finite (not NaN) datapoints over land\n",
    "N_data=len(TROPO_sif_data[(np.isnan(TROPO_sif_data)==False) & (np.isnan(Adjusted_CSIF)==False) & (Land_Data.T<15)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove NaN data from data from cropland CSIF (i.e. remove datapoints not over croplands)\n",
    "CSIF_Crops_narm=CSIF_Crops[np.isnan(CSIF_Crops)==False]\n",
    "#Create an array of indices of data over croplands\n",
    "indx_list_Crops=list(range(0,len(CSIF_Crops_narm)))\n",
    "#make the number of samples proportional to the fraction of each land cover type\n",
    "CSIF_Crops_indx=np.random.choice(indx_list_Crops,size=int(50000*len(indx_list_Crops)/N_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for rural and Urban\n",
    "\n",
    "CSIF_Rural_narm=CSIF_Rural[np.isnan(CSIF_Rural)==False]\n",
    "indx_list_Rural=list(range(0,len(CSIF_Rural_narm)))\n",
    "#make the number of samples proportional to the fraction of each land cover type\n",
    "CSIF_Rural_indx=np.random.choice(indx_list_Rural,size=int(50000*len(indx_list_Rural)/N_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSIF_Urban_narm=CSIF_Urban[np.isnan(CSIF_Urban)==False]\n",
    "indx_list_Urban=list(range(0,len(CSIF_Urban_narm)))\n",
    "#make the number of samples proportional to the fraction of each land cover type\n",
    "CSIF_Urban_indx=np.random.choice(indx_list_Urban,size=int(50000*len(indx_list_Urban)/N_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('tableau-colorblind10')\n",
    "plt.rc('font',size=16)\n",
    "\n",
    "plt.figure(figsize=(7.75,7.75))\n",
    "plt.xlim(-0.75,2)\n",
    "plt.ylim(-0.75,2)\n",
    "plt.axis('scaled')\n",
    "plt.scatter(TROPO_sif_data[np.isnan(CSIF_Crops)==False][CSIF_Crops_indx],CSIF_Crops_narm[CSIF_Crops_indx],s=2)\n",
    "plt.scatter([-10],[-10],s=20,c='#006BA4',label='Croplands')\n",
    "plt.scatter(TROPO_sif_data[np.isnan(CSIF_Rural)==False][CSIF_Rural_indx],CSIF_Rural_narm[CSIF_Rural_indx],s=2)\n",
    "plt.scatter([-10],[-10],s=20,c='#FF800E',label='Rural')\n",
    "plt.scatter(TROPO_sif_data[np.isnan(CSIF_Urban)==False][CSIF_Urban_indx],CSIF_Urban_narm[CSIF_Urban_indx],s=2)\n",
    "plt.scatter([-10],[-10],s=20,c='#ABABAB',label='Urban')\n",
    "plt.axvline(0,c='k',linestyle=':')\n",
    "plt.axhline(0,c='k',linestyle=':')\n",
    "plt.plot(line1_1,func2(line1_1,np.nanmean(Huber_slps),np.nanmean(Huber_ints)),c='#595959',linestyle='--',label=str(np.round(np.nanmean(Huber_slps),2))+'$\\cdot$x+'+str(np.round(np.nanmean(Huber_ints),2))+', R$^2$ = '+str(np.round(Huber_R2,2)))\n",
    "plt.plot(line1_1,func2(line1_1,1,0),linestyle='-.',c='k',label='1:1, R$^2$ = '+str(np.round(R2_1_1,2)))\n",
    "plt.legend()\n",
    "plt.title('Downscaled CSIF vs. TROPOMI SIF, 2018')\n",
    "plt.xlabel('Downscaled TROPOMI SIF (mW m$^{-2}$ sr$^{-1}$ nm$^{-1}$)')\n",
    "plt.ylabel('Downscaled CSIF (mW m$^{-2}$ sr$^{-1}$ nm$^{-1}$)')\n",
    "# *** Uncomment to save the figure as png and pdf. CHANGE FILENAMEs ***\n",
    "#plt.savefig('Fixed_Downscaled_CSIF_vs_TROPOMI_SIF_V061_2018_GTA_Huber_fit_bootstraped_plot_less_data.pdf',bbox_inches='tight')\n",
    "#plt.savefig('Fixed_Downscaled_CSIF_vs_TROPOMI_SIF_V061_2018_GTA_Huber_fit_bootstraped_plot_less_data.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
